{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6fb0a653-2e9d-424c-851e-ac05ea036d75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from termcolor import colored, cprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d332f6ca-46b8-4a1d-8838-5f0a288b10ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Utiles: importation de données, enlever balises/espaces, chaines égales sans espaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7b85a6ba-c692-4dce-8dcd-ca46d360e8a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def afficher_paire_parag(paire_parag):\n",
    "    parag_source=paire_parag[0]\n",
    "    parag_cible=paire_parag[1]\n",
    "                          \n",
    "    print(\"Paragraphe source:\")\n",
    "    for ligne in parag_source:\n",
    "        cprint(ligne['text'], ligne['couleur'],end=ligne['sep'],flush=ligne['flush'])\n",
    "    print(\"\\nParagraphe cible:\")\n",
    "    for ligne in parag_cible:\n",
    "        cprint(ligne['text'], ligne['couleur'],end=ligne['sep'],flush=ligne['flush'])\n",
    "\n",
    "    print(\"----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9bd7257d-c28e-4441-a43a-261f445701ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def import_data(path,filename):\n",
    "    with open(path+filename, 'r') as article_file:\n",
    "        diff_article=[json.loads(line.strip('\\n')) for line in article_file]  \n",
    "    return diff_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "70209282-7e37-4fd2-be91-8d51d88e8c81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to remove specific tags\n",
    "def remove_tags(chaine):\n",
    "    balises = [\"[Figure]\", \"[Equation]\", \"[Table]\"]\n",
    "    for balise in balises:\n",
    "        chaine = chaine.replace(balise, \"\")\n",
    "    return chaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e43b2f01-e61f-437f-b86b-93737ccd214d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sont_egales_sans_espaces(chaine1, chaine2):\n",
    "    # Supprimer les espaces des deux chaînes\n",
    "    chaine1_sans_espaces = re.sub(r'\\s', '', chaine1)\n",
    "    chaine2_sans_espaces = re.sub(r'\\s', '', chaine2)\n",
    "\n",
    "    # Comparer les chaînes sans espaces\n",
    "    return chaine1_sans_espaces == chaine2_sans_espaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "59999e13-748f-4567-8029-8a770bab502a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def enlever_espaces(chaine):\n",
    "    # Supprimer les espaces des deux chaînes\n",
    "    chaine_sans_espaces = re.sub(r'\\s', '', chaine)\n",
    "\n",
    "    # Comparer les chaînes sans espaces\n",
    "    return chaine_sans_espaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "72402ee1-f5e5-44cb-98b5-3772b558506a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def recollage_parag_nocolor(parag_source,parag_cible):                          \n",
    "    end_with_space=True\n",
    "    parag_source_complet=\"\"\n",
    "    for ligne in parag_source:\n",
    "        if len(ligne)>0:\n",
    "            start_with_space=(ligne[0]==' ')\n",
    "            if end_with_space or start_with_space:\n",
    "                parag_source_complet+=ligne\n",
    "            else:\n",
    "                parag_source_complet+=' '\n",
    "                parag_source_complet+=ligne\n",
    "            end_with_space=(ligne[-1]==' ')\n",
    "    parag_cible_complet=\"\"\n",
    "    end_with_space=True\n",
    "    for ligne in parag_cible:\n",
    "        if len(ligne)>0:\n",
    "            start_with_space=(ligne[0]==' ')\n",
    "            if end_with_space or start_with_space:\n",
    "                parag_cible_complet+=ligne\n",
    "            else:\n",
    "                parag_cible_complet+=' '\n",
    "                parag_cible_complet+=ligne\n",
    "            end_with_space=(ligne[-1]==' ')\n",
    "    return  parag_source_complet,parag_cible_complet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fa3562-6dab-4dd4-8115-641a42fd86b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Préparation: Découpage en paires de paragraphes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f01daab9-0cd8-486f-8449-9a0b5dba66cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calcul_longeur_modif(phrase,sentence_token_indices):\n",
    "    debut_sent=0\n",
    "    fin_sent=0\n",
    "    if type(sentence_token_indices)==list:\n",
    "        debut_sent=sentence_token_indices[0]\n",
    "        fin_sent=sentence_token_indices[1]\n",
    "        extracted_edit=remove_tags(phrase[debut_sent:fin_sent])\n",
    "        \n",
    "        longeur_modif=len(extracted_edit)#fin_sent-debut_sent\n",
    "    else:\n",
    "        longeur_modif=0\n",
    "    \n",
    "    return longeur_modif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "16bc753d-100d-4704-b3f8-a8bc4a2459e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calcul_pourcentages_modifs(element):\n",
    "    longeur_modif_1=0\n",
    "    longeur_modif_2=0\n",
    "    for idx_elt in range(len(element['edits-combination'])):\n",
    "        if type(element['edits-combination'][str(idx_elt)]['sentence-1-token-indices'])==list and type(element['edits-combination'][str(idx_elt)]['sentence-2-token-indices'])==list:\n",
    "            debut_sent1=element['edits-combination'][str(idx_elt)]['sentence-1-token-indices'][0]\n",
    "            fin_sent1=element['edits-combination'][str(idx_elt)]['sentence-1-token-indices'][1]\n",
    "            debut_sent2=element['edits-combination'][str(idx_elt)]['sentence-2-token-indices'][0]\n",
    "            fin_sent2=element['edits-combination'][str(idx_elt)]['sentence-2-token-indices'][1]\n",
    "\n",
    "            if not(sont_egales_sans_espaces(element['text-sentence-1'][debut_sent1:fin_sent1],element['text-sentence-2'][debut_sent2:fin_sent2])):\n",
    "                longeur_modif_1+=calcul_longeur_modif(element['text-sentence-1'],element['edits-combination'][str(idx_elt)]['sentence-1-token-indices'])\n",
    "                longeur_modif_2+=calcul_longeur_modif(element['text-sentence-2'],element['edits-combination'][str(idx_elt)]['sentence-2-token-indices'])\n",
    "        else:\n",
    "            longeur_modif_1+=calcul_longeur_modif(element['text-sentence-1'],element['edits-combination'][str(idx_elt)]['sentence-1-token-indices'])\n",
    "            longeur_modif_2+=calcul_longeur_modif(element['text-sentence-2'],element['edits-combination'][str(idx_elt)]['sentence-2-token-indices'])\n",
    "\n",
    "    #Calcul des pourcentages modifs\n",
    "    longueur_phrase_1_ss_balise=len(remove_tags(element['text-sentence-1']))\n",
    "    longueur_phrase_2_ss_balise=len(remove_tags(element['text-sentence-2']))\n",
    "    if longueur_phrase_1_ss_balise>0:\n",
    "        pourcentage_modif_1=longeur_modif_1/longueur_phrase_1_ss_balise\n",
    "    else:\n",
    "        pourcentage_modif_1=0\n",
    "    if longueur_phrase_2_ss_balise>0:\n",
    "        pourcentage_modif_2=longeur_modif_2/longueur_phrase_2_ss_balise\n",
    "    else:\n",
    "        pourcentage_modif_2=0\n",
    "        \n",
    "    return pourcentage_modif_1,pourcentage_modif_2,longueur_phrase_1_ss_balise,longueur_phrase_2_ss_balise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5b53fe68-aa70-47bc-a0fc-d4bd141e7380",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_new_num_section(element):\n",
    "    if \"num_section-sentence-1\" in element:\n",
    "        new_num_section_1=element[\"num_section-sentence-1\"]\n",
    "    else:\n",
    "        new_num_section_1=-2\n",
    "    if \"num_section-sentence-2\" in element:\n",
    "        new_num_section_2=element[\"num_section-sentence-2\"]\n",
    "    else:\n",
    "        new_num_section_2=-2\n",
    "    return new_num_section_1,new_num_section_2         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1986a4fd-2a89-427d-91ca-94a86da990e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_num_parag(element):\n",
    "    if \"num_paragraph-sentence-1\" in element:\n",
    "        new_num_parag_1=element[\"num_paragraph-sentence-1\"]\n",
    "    else:\n",
    "        if \"id-sentence-1\" in element:\n",
    "            new_num_parag_1=-1\n",
    "        else:\n",
    "            new_num_parag_1=-2\n",
    "    if \"num_paragraph-sentence-2\" in element:\n",
    "        new_num_parag_2=element[\"num_paragraph-sentence-2\"]\n",
    "    else:\n",
    "        if \"id-sentence-2\" in element:\n",
    "            new_num_parag_2=-1\n",
    "        else:\n",
    "            new_num_parag_2=-2\n",
    "    return new_num_parag_1,new_num_parag_2         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "52f5e49e-1bc9-446e-95ab-9df445975a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_paires_parag(diff_article,seuil_bas=0.5):\n",
    "    #Initialisations\n",
    "    old_num_parag_1=-1\n",
    "    old_num_parag_2=-1\n",
    "    old_num_section_1=-1\n",
    "    old_num_section_2=-1\n",
    "    aggreg_parag_1=[]\n",
    "    aggreg_parag_2=[]\n",
    "    \n",
    "    liste_sections=[]\n",
    "    liste_paires_parag=[]\n",
    "    cpt_parag_trop_petits=0\n",
    "    for element in diff_article:\n",
    "        \n",
    "        new_num_section_1,new_num_section_2=get_new_num_section(element)\n",
    "        \n",
    "        new_num_parag_1,new_num_parag_2=get_new_num_parag(element)\n",
    "        \n",
    "        section_les_deux_changent=(old_num_section_1!=new_num_section_1) and (old_num_section_2!=new_num_section_2)\n",
    "        section_source_change_cible_vide=(old_num_section_1!=new_num_section_1) and (old_num_section_2+new_num_section_2==-4)\n",
    "        section_source_vide_cible_change=(old_num_section_1+new_num_section_1==-4) and (old_num_section_2!=new_num_section_2)\n",
    "        \n",
    "        parag_les_deux_changent=(old_num_parag_1!=new_num_parag_1) and (old_num_parag_2!=new_num_parag_2)\n",
    "        parag_source_change_cible_vide=(old_num_parag_1!=new_num_parag_1) and (old_num_parag_2+new_num_parag_2==-4)\n",
    "        parag_source_vide_cible_change=(old_num_parag_1+new_num_parag_1==-4) and (old_num_parag_2!=new_num_parag_2)\n",
    "        \n",
    "        if section_les_deux_changent or section_source_change_cible_vide or section_source_vide_cible_change:\n",
    "            liste_paires_parag.append((aggreg_parag_1,aggreg_parag_2))\n",
    "\n",
    "            aggreg_parag_1=[]\n",
    "            aggreg_parag_2=[]\n",
    "            liste_sections.append(liste_paires_parag)\n",
    "            liste_paires_parag=[]\n",
    "        elif parag_les_deux_changent or parag_source_change_cible_vide or parag_source_vide_cible_change:\n",
    "            liste_paires_parag.append((aggreg_parag_1,aggreg_parag_2))\n",
    "            \n",
    "            aggreg_parag_1=[]\n",
    "            aggreg_parag_2=[]\n",
    "\n",
    "        old_num_section_1=new_num_section_1\n",
    "        old_num_section_2=new_num_section_2  \n",
    "        \n",
    "        old_num_parag_1=new_num_parag_1\n",
    "        old_num_parag_2=new_num_parag_2        \n",
    "                      \n",
    "        pourcentage_modif_1,pourcentage_modif_2,longueur_phrase_1,longueur_phrase_2=calcul_pourcentages_modifs(element)\n",
    "        prct1_round=round(pourcentage_modif_1*100,2)\n",
    "        prct2_round=round(pourcentage_modif_2*100,2)\n",
    "        #Cas I vert\n",
    "        if len(element['edits-combination'])==0:\n",
    "            #Cas I.1 vert après autre couleur (jaune/rouge)\n",
    "            aggreg_parag_1.append({\"text\":str(new_num_parag_1)+\"|\"+str(len(element['text-sentence-1']))+\"-\"+str(longueur_phrase_1)+\"|\",\"couleur\":'black',\"sep\":'',\"flush\":True,\"longueur\":longueur_phrase_1})\n",
    "            aggreg_parag_2.append({\"text\":str(new_num_parag_2)+\"|\"+str(len(element['text-sentence-2']))+\"-\"+str(longueur_phrase_2)+\"|\",\"couleur\":'black',\"sep\":'',\"flush\":True,\"longueur\":longueur_phrase_2})\n",
    "           \n",
    "            aggreg_parag_1.append({\"text\":element['text-sentence-1'],\"couleur\":'green',\"sep\":'\\n',\"flush\":False})\n",
    "            aggreg_parag_2.append({\"text\":element['text-sentence-1'],\"couleur\":'green',\"sep\":'\\n',\"flush\":False})\n",
    "\n",
    "        #Cas II bleu\n",
    "        elif (pourcentage_modif_1<seuil_bas) and (pourcentage_modif_2<seuil_bas):\n",
    "            #Imprimer en bleu les zones modifiées et en vert les autres\n",
    "            fin_prec_1=0\n",
    "            fin_prec_2=0\n",
    "            liste_intentions=[]\n",
    "            for idx_elt in range(len(element['edits-combination'])):\n",
    "                liste_intentions.append(element['edits-combination'][str(idx_elt)][\"intention\"])\n",
    "            liste_intentions=list(set(liste_intentions))\n",
    "            aggreg_parag_1.append({\"list_intentions\":liste_intentions,\"text\":str(new_num_parag_1)+\"|\"+str(len(element['text-sentence-1']))+\"-\"+str(longueur_phrase_1)+\"|\"+str(prct1_round)+\" \"+str(prct2_round),\"couleur\":'black',\"sep\":'',\"flush\":True,\"longueur\":longueur_phrase_1,\"prct_modif\":prct1_round})\n",
    "            aggreg_parag_2.append({\"list_intentions\":liste_intentions,\"text\":str(new_num_parag_2)+\"|\"+str(len(element['text-sentence-2']))+\"-\"+str(longueur_phrase_2)+\"|\"+str(prct1_round)+\" \"+str(prct2_round),\"couleur\":'black',\"sep\":'',\"flush\":True,\"longueur\":longueur_phrase_2,\"prct_modif\":prct2_round})\n",
    "                  \n",
    "            for idx_elt in range(len(element['edits-combination'])):\n",
    "                debut_sent1=0\n",
    "                fin_sent1=0\n",
    "                         \n",
    "                if type(element['edits-combination'][str(idx_elt)]['sentence-1-token-indices'])==list:\n",
    "                    debut_sent1=element['edits-combination'][str(idx_elt)]['sentence-1-token-indices'][0]\n",
    "                    fin_sent1=element['edits-combination'][str(idx_elt)]['sentence-1-token-indices'][1]\n",
    "                    \n",
    "                    if type(element['edits-combination'][str(idx_elt)]['sentence-2-token-indices'])==list:\n",
    "                        debut_sent2=element['edits-combination'][str(idx_elt)]['sentence-2-token-indices'][0]\n",
    "                        fin_sent2=element['edits-combination'][str(idx_elt)]['sentence-2-token-indices'][1]\n",
    "\n",
    "                        if sont_egales_sans_espaces(element['text-sentence-1'][debut_sent1:fin_sent1],element['text-sentence-2'][debut_sent2:fin_sent2]):\n",
    "                            aggreg_parag_1.append({\"text\":element['text-sentence-1'][fin_prec_1:debut_sent1],\"couleur\":'cyan',\"sep\":'',\"flush\":True})\n",
    "                            aggreg_parag_1.append({\"text\":element['text-sentence-1'][debut_sent1:fin_sent1],\"couleur\":'cyan',\"sep\":'',\"flush\":True})\n",
    "                        else:\n",
    "                            aggreg_parag_1.append({\"text\":element['text-sentence-1'][fin_prec_1:debut_sent1],\"couleur\":'cyan',\"sep\":'',\"flush\":True})\n",
    "                            aggreg_parag_1.append({\"text\":element['text-sentence-1'][debut_sent1:fin_sent1],\"couleur\":'blue',\"sep\":'',\"flush\":True})\n",
    "\n",
    "                    else:\n",
    "                        aggreg_parag_1.append({\"text\":element['text-sentence-1'][fin_prec_1:debut_sent1],\"couleur\":'cyan',\"sep\":'',\"flush\":True})\n",
    "                        aggreg_parag_1.append({\"text\":element['text-sentence-1'][debut_sent1:fin_sent1],\"couleur\":'blue',\"sep\":'',\"flush\":True})\n",
    "                    fin_prec_1=fin_sent1\n",
    "            aggreg_parag_1.append({\"text\":element['text-sentence-1'][fin_prec_1:],\"couleur\":'cyan',\"sep\":'\\n',\"flush\":False})\n",
    "                \n",
    "            for idx_elt in range(len(element['edits-combination'])):\n",
    "                debut_sent2=0\n",
    "                fin_sent2=0\n",
    "                                     \n",
    "                if type(element['edits-combination'][str(idx_elt)]['sentence-2-token-indices'])==list:\n",
    "                    debut_sent2=element['edits-combination'][str(idx_elt)]['sentence-2-token-indices'][0]\n",
    "                    fin_sent2=element['edits-combination'][str(idx_elt)]['sentence-2-token-indices'][1]\n",
    "                    \n",
    "                    if type(element['edits-combination'][str(idx_elt)]['sentence-1-token-indices'])==list:\n",
    "                        debut_sent1=element['edits-combination'][str(idx_elt)]['sentence-1-token-indices'][0]\n",
    "                        fin_sent1=element['edits-combination'][str(idx_elt)]['sentence-1-token-indices'][1]\n",
    "                        if sont_egales_sans_espaces(element['text-sentence-1'][debut_sent1:fin_sent1],element['text-sentence-2'][debut_sent2:fin_sent2]):\n",
    "                            aggreg_parag_2.append({\"text\":element['text-sentence-2'][fin_prec_2:debut_sent2],\"couleur\":'cyan',\"sep\":'',\"flush\":True})\n",
    "                            aggreg_parag_2.append({\"text\":element['text-sentence-2'][debut_sent2:fin_sent2],\"couleur\":'cyan',\"sep\":'',\"flush\":True})\n",
    "                        else:\n",
    "                            aggreg_parag_2.append({\"text\":element['text-sentence-2'][fin_prec_2:debut_sent2],\"couleur\":'cyan',\"sep\":'',\"flush\":True})\n",
    "                            aggreg_parag_2.append({\"text\":element['text-sentence-2'][debut_sent2:fin_sent2],\"couleur\":'blue',\"sep\":'',\"flush\":True})\n",
    "                    else:\n",
    "                        \n",
    "                        aggreg_parag_2.append({\"text\":element['text-sentence-2'][fin_prec_2:debut_sent2],\"couleur\":'cyan',\"sep\":'',\"flush\":True})\n",
    "                        aggreg_parag_2.append({\"text\":element['text-sentence-2'][debut_sent2:fin_sent2],\"couleur\":'blue',\"sep\":'',\"flush\":True})\n",
    "                    fin_prec_2=fin_sent2\n",
    "            aggreg_parag_2.append({\"text\":element['text-sentence-2'][fin_prec_2:],\"couleur\":'cyan',\"sep\":'\\n',\"flush\":False})\n",
    "                \n",
    "            reset=True\n",
    "        #Cas III: rouge/jaune\n",
    "        else:\n",
    "            liste_intentions=[]\n",
    "            for idx_elt in range(len(element['edits-combination'])):\n",
    "                liste_intentions.append(element['edits-combination'][str(idx_elt)][\"intention\"])\n",
    "            liste_intentions=list(set(liste_intentions))\n",
    "            aggreg_parag_1.append({\"list_intentions\":liste_intentions,\"text\":str(new_num_parag_1)+\"|\"+str(len(element['text-sentence-1']))+\"-\"+str(longueur_phrase_1)+\"|\"+str(prct1_round)+\" \"+str(prct2_round),\"couleur\":'black',\"sep\":'',\"flush\":True,\"longueur\":longueur_phrase_1,\"prct_modif\":prct1_round})\n",
    "            aggreg_parag_1.append({\"text\":element['text-sentence-1'],\"couleur\":'yellow',\"sep\":'\\n',\"flush\":False})\n",
    "            \n",
    "            aggreg_parag_2.append({\"list_intentions\":liste_intentions,\"text\":str(new_num_parag_2)+\"|\"+str(len(element['text-sentence-2']))+\"-\"+str(longueur_phrase_2)+\"|\"+str(prct1_round)+\" \"+str(prct2_round),\"couleur\":'black',\"sep\":'',\"flush\":True,\"longueur\":longueur_phrase_2,\"prct_modif\":prct2_round})\n",
    "            aggreg_parag_2.append({\"text\":element['text-sentence-2'],\"couleur\":'red',\"sep\":'\\n',\"flush\":False})\n",
    "    \n",
    "    return liste_sections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d546d6ab-6c7b-4bdb-9d11-c3394d4080fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Filtre: long enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1c3dd4cb-d4e9-42af-9841-7e2abef0d14f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_long_enough(paire_parag,longueur_minimum=250):    \n",
    "    parag_source=[element for element in paire_parag[0] if element['couleur']==\"black\" ]\n",
    "    parag_cible=[element for element in paire_parag[1] if element['couleur']==\"black\" ]\n",
    "    longeur_parag_1=sum([ligne_source[\"longueur\"] for ligne_source in parag_source])\n",
    "    longeur_parag_2=sum([ligne_cible[\"longueur\"] for ligne_cible in parag_cible])\n",
    "    \n",
    "    return (max(longeur_parag_1,longeur_parag_2)>longueur_minimum)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b3c988-e7aa-4082-8244-9601cd2ccf71",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Filtre: Respect limites modifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "60ee3bfd-322a-4892-800d-1675ec9dfdb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def respect_limit_modifs(paire_parag, prct_mini_phrase=25,prct_mini_parag=10, prct_maxi=90, lg_modif_maxi=200,prct_maxi_parag=40):\n",
    "    parag_source=[element for element in paire_parag[0] if element['couleur']==\"black\" ]        \n",
    "    parag_cible=[element for element in paire_parag[1] if element['couleur']==\"black\" ]\n",
    "    all_colors=set([ligne_source[\"couleur\"] for ligne_source in paire_parag[0]]+[ligne_cible[\"couleur\"] for ligne_cible in paire_parag[1]])\n",
    "    prct_modif_max=max([0]+[max(ligne_source[\"prct_modif\"],ligne_cible[\"prct_modif\"]) for (ligne_source, ligne_cible) in zip(parag_source, parag_cible) if \"prct_modif\" in ligne_source.keys()])\n",
    "    longueur_plus_maxi_parag1=sum([ligne_source[\"longueur\"] for (ligne_source, ligne_cible) in zip(parag_source, parag_cible) if (\"prct_modif\" in ligne_source.keys() and max(ligne_source[\"prct_modif\"],ligne_cible[\"prct_modif\"])>prct_maxi) ])\n",
    "    longueur_plus_maxi_parag2=sum([ligne_cible[\"longueur\"] for (ligne_source, ligne_cible) in zip(parag_source, parag_cible) if (\"prct_modif\" in ligne_source.keys() and max(ligne_source[\"prct_modif\"],ligne_cible[\"prct_modif\"])>prct_maxi) ])\n",
    "    longueur_totale_parag1=sum([ligne_source[\"longueur\"] for ligne_source in parag_source])\n",
    "    longueur_totale_parag2=sum([ligne_cible[\"longueur\"] for ligne_cible in parag_cible])\n",
    "   \n",
    "    longueur_modif_parag1=sum([ligne_source[\"prct_modif\"]*ligne_source[\"longueur\"] for (ligne_source, ligne_cible) in zip(parag_source, parag_cible) if \"prct_modif\" in ligne_source.keys()])\n",
    "    longueur_modif_parag2=sum([ligne_cible[\"prct_modif\"]*ligne_cible[\"longueur\"] for (ligne_source, ligne_cible) in zip(parag_source, parag_cible) if \"prct_modif\" in ligne_source.keys()])\n",
    "\n",
    "    if longueur_totale_parag1>0:\n",
    "        prct_modif_parag1=longueur_modif_parag1/longueur_totale_parag1\n",
    "    else:\n",
    "        prct_modif_parag1=0\n",
    "    if longueur_totale_parag2>0:\n",
    "        prct_modif_parag2=longueur_modif_parag2/longueur_totale_parag2\n",
    "    else:\n",
    "        prct_modif_parag2=0\n",
    "        \n",
    "    if longueur_totale_parag1==0 and longueur_totale_parag2==0:\n",
    "        return False\n",
    "    elif longueur_totale_parag1==0:\n",
    "        trop_de_modif=(longueur_plus_maxi_parag2/longueur_totale_parag2<prct_maxi_parag/100)\n",
    "    elif longueur_totale_parag2==0:\n",
    "        trop_de_modif=(longueur_plus_maxi_parag1/longueur_totale_parag1<prct_maxi_parag/100)\n",
    "    else:\n",
    "        trop_de_modif=(max(longueur_plus_maxi_parag1/longueur_totale_parag1,longueur_plus_maxi_parag2/longueur_totale_parag2)<prct_maxi_parag/100)\n",
    "    \n",
    "    trop_de_modif=trop_de_modif or (max(longueur_plus_maxi_parag1,longueur_plus_maxi_parag2)<lg_modif_maxi)\n",
    "    \n",
    "    if len(all_colors.intersection({\"yellow\",\"red\"}))==0:\n",
    "        prct_mini_blue_only=20\n",
    "        longueur_phrases_modif_parag1=sum([ligne_source[\"longueur\"] for ligne_source in parag_source if (\"prct_modif\" in ligne_source.keys() ) ])\n",
    "        longueur_phrases_modif_parag2=sum([ligne_cible[\"longueur\"] for ligne_cible in parag_cible if (\"prct_modif\" in ligne_cible.keys() )])\n",
    "        if longueur_phrases_modif_parag1>0:\n",
    "            prct_modif_parag1_blue=longueur_modif_parag1/longueur_phrases_modif_parag1\n",
    "        else:\n",
    "            prct_modif_parag1_blue=0\n",
    "        if longueur_phrases_modif_parag2>0:\n",
    "            prct_modif_parag2_blue=longueur_modif_parag2/longueur_phrases_modif_parag2\n",
    "        else:\n",
    "            prct_modif_parag2_blue=0\n",
    "        if \"green\" in all_colors:\n",
    "            return  prct_modif_max>prct_mini_phrase and trop_de_modif and max(prct_modif_parag1,prct_modif_parag2)> prct_mini_parag and max(prct_modif_parag1_blue,prct_modif_parag2_blue)> prct_mini_blue_only \n",
    "        else:\n",
    "            return  prct_modif_max>prct_mini_phrase and trop_de_modif and max(prct_modif_parag1_blue,prct_modif_parag2_blue)> prct_mini_blue_only \n",
    "    else:\n",
    "        return  prct_modif_max>prct_mini_phrase and trop_de_modif and max(prct_modif_parag1,prct_modif_parag2)> prct_mini_parag        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3bda64-5aae-4d38-a577-8b5653f19e9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Filtre: équations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7691d8d8-314b-4b50-a872-6db6bf5d2887",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_special_characters(paragraph):\n",
    "    # Define a list of special characters and patterns to count\n",
    "    special_patterns = [\n",
    "        r'\\(cid:\\d+\\)',  # Matches (cid:xx) where x are numbers\n",
    "        \"\\[Equation\\]\",\n",
    "        r'\\s[A-Za-z]\\s',  # Matches individual letters surrounded by spaces\n",
    "        r'\\s\\(\\s', r'\\s\\)\\s', '\\=', '\\+', '\\/'\n",
    "    ]\n",
    "    # Count the occurrences of each special character or pattern in the paragraph\n",
    "    character_counts = {pattern: len(re.findall(pattern, paragraph)) for pattern in special_patterns}\n",
    "\n",
    "    return character_counts\n",
    "\n",
    "def contains_too_many_equations(paire_parag, threshold=11):\n",
    "    # Extract draft and revised paragraphs from the pair\n",
    "    draft_paragraph=' '.join([element[\"text\"] for element in paire_parag[0] if (element['couleur']!=\"black\")])\n",
    "    revised_paragraph=' '.join([element[\"text\"] for element in paire_parag[1] if (element['couleur']!=\"black\")])\n",
    "    #Extract only the rewritten sentences\n",
    "    draft_paragraph_no_green=' '.join([element[\"text\"] for element in paire_parag[0] if (element['couleur']!=\"green\" and element['couleur']!=\"black\")])\n",
    "    revised_paragraph_no_green=' '.join([element[\"text\"] for element in paire_parag[1] if (element['couleur']!=\"green\" and element['couleur']!=\"black\")])\n",
    "\n",
    "    # Count special characters in each paragraph\n",
    "    draft_character_counts = count_special_characters(draft_paragraph)\n",
    "    revised_character_counts = count_special_characters(revised_paragraph)\n",
    "    # Count special characters in each paragraph only in rewritten sentences\n",
    "    draft_character_counts_no_green = count_special_characters(draft_paragraph_no_green)\n",
    "    revised_character_counts_no_green = count_special_characters(revised_paragraph_no_green)\n",
    "\n",
    "    # Calculate the total count of special characters in each paragraph\n",
    "    draft_total_count = 2*sum(draft_character_counts.values())+ 7*draft_character_counts[\"\\\\(cid:\\\\d+\\\\)\"]+ 9*draft_character_counts[\"\\\\[Equation\\\\]\"]\n",
    "    revised_total_count = 2*sum(revised_character_counts.values())+ 7*revised_character_counts[\"\\\\(cid:\\\\d+\\\\)\"]+9*revised_character_counts[\"\\\\[Equation\\\\]\"]\n",
    "    draft_total_count_no_green = 2*sum(draft_character_counts_no_green.values())+ 7*draft_character_counts_no_green[\"\\\\(cid:\\\\d+\\\\)\"]+ 9*draft_character_counts_no_green[\"\\\\[Equation\\\\]\"]\n",
    "    revised_total_count_no_green = 2*sum(revised_character_counts_no_green.values())+ 7*revised_character_counts_no_green[\"\\\\(cid:\\\\d+\\\\)\"]+ 9*revised_character_counts_no_green[\"\\\\[Equation\\\\]\"]\n",
    "\n",
    "    # Check if either paragraph has too many special characters\n",
    "    #Case 1: Perfectly identical paragraph, never happen\n",
    "    if len(draft_paragraph_no_green)==0 and len(revised_paragraph_no_green)==0:\n",
    "        if len(draft_paragraph)==0:\n",
    "            return revised_total_count*100/len(revised_paragraph)>threshold\n",
    "        elif len(revised_paragraph)==0:\n",
    "            return draft_total_count*100/len(draft_paragraph)>threshold\n",
    "        else:\n",
    "            return draft_total_count*100/len(draft_paragraph)>threshold or revised_total_count*100/len(revised_paragraph)>threshold\n",
    "    #Case 2 : Only additions\n",
    "    elif len(draft_paragraph_no_green)==0:\n",
    "        return revised_total_count_no_green*100/len(revised_paragraph_no_green)>threshold\n",
    "    #Case 3 : Only deletions\n",
    "    elif len(revised_paragraph_no_green)==0:\n",
    "        return draft_total_count_no_green*100/len(draft_paragraph_no_green)>threshold\n",
    "    #Case 4: Both deletions and additions\n",
    "    else:\n",
    "        if draft_total_count_no_green*100/len(draft_paragraph_no_green)>threshold or revised_total_count_no_green*100/len(revised_paragraph_no_green)>threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e587b5b-d583-4a2b-919c-895823e3108d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Filtre: Diff sur première ou dernière phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8b3f5fa7-a69d-4c5f-bd39-52d706fa0a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_incorrect_beginning(sentence):\n",
    "    return (re.match(r'^[^a-zA-Z]*[A-Z]', sentence) is None)\n",
    "# Check if the ending of the sentence is correct. \n",
    "# aka Finish with a punctuation mark, spaces and url are accepted after the final punctuation\n",
    "def check_incorrect_ending(sentence):\n",
    "    #TODO rajouter un point pour les url avec que des points\n",
    "    return (re.match(r'.*([\\.\\?!:]\\s*$|\\.[a-zA-Z/.]+\\s*$)', sentence) is None)\n",
    "def check_incorrect_beginning_ending(sentence):\n",
    "    return (re.match(r'^[^a-zA-Z]*[A-Z].*([\\.\\?!:]\\s*$|\\.[a-zA-Z/.]+\\s*$)', sentence) is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c26368cf-6e06-49a3-9b42-737690e18856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return true if there is a problem detected in the last sentence\n",
    "def last_is_problem(phrase_source,phrase_cible):\n",
    "    #Remove the tags\n",
    "    phrase_source_no_tag=remove_tags(phrase_source[\"text\"])\n",
    "    phrase_cible_no_tag=remove_tags(phrase_cible[\"text\"])\n",
    "    #Remove tags and spaces\n",
    "    phrase_source_condens=enlever_espaces(remove_tags(phrase_source[\"text\"]))\n",
    "    phrase_cible_condens=enlever_espaces(remove_tags(phrase_cible[\"text\"]))\n",
    "\n",
    "    #If the source sentence is not empty, does it have an incorrect ending?\n",
    "    fin_1_ko= (len(phrase_source[\"text\"])>0) and check_incorrect_ending(phrase_source_no_tag)\n",
    "    #If the target sentence is not empty, does it have an incorrect ending?\n",
    "    fin_2_ko= (len(phrase_cible[\"text\"])>0) and check_incorrect_ending(phrase_cible_no_tag)\n",
    "    #If one of the sentences have an incorrect ending, exit the function with True\n",
    "    if fin_1_ko or fin_2_ko:\n",
    "        return True\n",
    "    \n",
    "    #Case 1: Heavy change\n",
    "    if (phrase_source[\"couleur\"]==\"yellow\") and (phrase_cible[\"couleur\"]==\"red\"):\n",
    "    #Est ce quele plus grand est plus petit que 3 fois le plus petit?\n",
    "        #Case A: The target is longer\n",
    "        if phrase_source_condens<phrase_cible_condens:\n",
    "            #Is the source equal to the beginning of the target?\n",
    "            is_included= (phrase_cible_condens[0:len(phrase_source_condens)]==phrase_source_condens)\n",
    "            #Is the target more than 3 time the length of the source? (Too much text difference)\n",
    "            is_too_long=(len(phrase_cible_condens)>3*len(phrase_source_condens))\n",
    "            return is_included or is_too_long\n",
    "        #Case B: The source is longer\n",
    "        else:\n",
    "            #Is the target equal to the beginning of the source?\n",
    "            is_included= (phrase_source_condens[0:len(phrase_cible_condens)]==phrase_cible_condens)\n",
    "            #Is the source more than 3 time the length of the target? (Too much text difference)\n",
    "            is_too_long=(len(phrase_source_condens)>3*len(phrase_cible_condens))\n",
    "            return  is_included or is_too_long\n",
    "    #Case 2: Moderate change or no change, if moderate change, correctness of ending have been checked previously\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ecb69e5e-963d-4bb0-adba-b334a67c6a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return true if there is a problem detected in the last sentence\n",
    "def last_is_problem_extended(phrase_source,phrase_cible):\n",
    "    #Remove the tags\n",
    "    phrase_source_no_tag=remove_tags(phrase_source[\"text\"])\n",
    "    phrase_cible_no_tag=remove_tags(phrase_cible[\"text\"])\n",
    "    #Remove tags and spaces\n",
    "    phrase_source_condens=enlever_espaces(remove_tags(phrase_source[\"text\"]))\n",
    "    phrase_cible_condens=enlever_espaces(remove_tags(phrase_cible[\"text\"]))\n",
    "\n",
    "    #If the source sentence is not empty, does it have an incorrect ending?\n",
    "    fin_1_ko= (len(phrase_source[\"text\"])>0) and check_incorrect_ending(phrase_source_no_tag)\n",
    "    #If the target sentence is not empty, does it have an incorrect ending?\n",
    "    fin_2_ko= (len(phrase_cible[\"text\"])>0) and check_incorrect_ending(phrase_cible_no_tag)\n",
    "    #If one of the sentences have an incorrect ending, exit the function with True\n",
    "    if fin_1_ko or fin_2_ko:\n",
    "        return True\n",
    "    \n",
    "    #Case 1: Deletion of a sentence\n",
    "    if (phrase_source[\"couleur\"]==\"yellow\") and ((phrase_cible[\"couleur\"]!=\"red\") or len(phrase_cible[\"text\"])==0):                                                \n",
    "        return check_incorrect_beginning_ending(phrase_source_no_tag)\n",
    "    #Case 2: Addition of a sentence\n",
    "    elif (phrase_cible[\"couleur\"]==\"red\") and ((phrase_source[\"couleur\"]!=\"yellow\") or len(phrase_source[\"text\"])==0):\n",
    "        return check_incorrect_beginning_ending(phrase_cible_no_tag)\n",
    "    #Cas 3: Heavy change\n",
    "    elif (phrase_source[\"couleur\"]==\"yellow\") and (phrase_cible[\"couleur\"]==\"red\"):\n",
    "    #Est ce quele plus grand est plus petit que 3 fois le plus petit?\n",
    "        #Case A: The target is longer\n",
    "        if phrase_source_condens<phrase_cible_condens:\n",
    "            #Is the source equal to the beginning of the target?\n",
    "            is_included= (phrase_cible_condens[0:len(phrase_source_condens)]==phrase_source_condens)\n",
    "            #Is the target more than 3 time the length of the source? (Too much text difference)\n",
    "            is_too_long=(len(phrase_cible_condens)>3*len(phrase_source_condens))\n",
    "            return is_included or is_too_long\n",
    "        #Case B: The source is longer\n",
    "        else:\n",
    "            #Is the target equal to the beginning of the source?\n",
    "            is_included= (phrase_source_condens[0:len(phrase_cible_condens)]==phrase_cible_condens)\n",
    "            #Is the source more than 3 time the length of the target? (Too much text difference)\n",
    "            is_too_long=(len(phrase_source_condens)>3*len(phrase_cible_condens))\n",
    "            return  is_included or is_too_long\n",
    "    #Case 4: Moderate change or no change, if moderate change, correctness of ending have been checked previously\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "de730d48-f5ff-43eb-9b90-89dd9c8a19ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_is_problem(phrase_source,phrase_cible):\n",
    "    #Remove the tags\n",
    "    phrase_source_no_tag=remove_tags(phrase_source[\"text\"])\n",
    "    phrase_cible_no_tag=remove_tags(phrase_cible[\"text\"])\n",
    "    #Remove tags and spaces\n",
    "    phrase_source_condens=enlever_espaces(remove_tags(phrase_source[\"text\"]))\n",
    "    phrase_cible_condens=enlever_espaces(remove_tags(phrase_cible[\"text\"]))\n",
    "    \n",
    "    #Cas que jaune\n",
    "    if len(phrase_source[\"text\"])>0:\n",
    "        #Check that the first alphabetical letter is a capital letter\n",
    "        debut_1_ko= check_incorrect_beginning(phrase_source_no_tag)\n",
    "    else:\n",
    "        debut_1_ko=False\n",
    "    if len(phrase_cible[\"text\"])>0:\n",
    "        debut_2_ko= check_incorrect_beginning(phrase_cible_no_tag)\n",
    "    else:\n",
    "        debut_2_ko=False\n",
    "    if debut_1_ko or debut_2_ko:\n",
    "        #Raise a problem in the first sentence is for one of them the first alphabetical letter is NOT a capital letter\n",
    "        return True\n",
    "    \n",
    "    if (phrase_source[\"couleur\"]==\"yellow\") and (len(phrase_cible[\"text\"])==0):\n",
    "        return len(phrase_source_condens)>0\n",
    "    #Cas que rouge\n",
    "    elif (phrase_cible[\"couleur\"]==\"red\") and (len(phrase_source[\"text\"])==0):\n",
    "        return len(phrase_cible_condens)>0\n",
    "    #Cas jaune et rouge \n",
    "    elif (phrase_source[\"couleur\"]==\"yellow\") and (phrase_cible[\"couleur\"]==\"red\"):\n",
    "        #est ce que le plus petit est égal à la fin du plus grand\n",
    "        if phrase_source_condens<phrase_cible_condens:\n",
    "            #Is the source equal to the end of the target?\n",
    "            is_included=phrase_cible_condens[len(phrase_cible_condens)-len(phrase_source_condens):len(phrase_cible_condens)]==phrase_source_condens\n",
    "            #Is the target more than 3 time the length of the source? (Too much text difference)\n",
    "            is_too_long=(len(phrase_cible_condens)>3*len(phrase_source_condens))\n",
    "            return is_too_long or is_included\n",
    "        else:\n",
    "            #Is the target equal to the end of the source?\n",
    "            is_included=phrase_source_condens[len(phrase_source_condens)-len(phrase_cible_condens):len(phrase_source_condens)]==phrase_cible_condens\n",
    "            #Is the source more than 3 time the length of the target? (Too much text difference)\n",
    "            is_too_long=(len(phrase_source_condens)>3*len(phrase_cible_condens))\n",
    "            return  is_too_long or is_included\n",
    "    #Cas bleu:\n",
    "    elif (phrase_source[\"couleur\"] in [\"blue\",\"cyan\"]):\n",
    "        #Cas bleu modif\n",
    "        #est ce que le plus petit est égal à la fin du plus grand\n",
    "        if (phrase_source[\"couleur\"]==\"blue\") and (phrase_cible[\"couleur\"]==\"blue\"):\n",
    "            if phrase_source_condens<phrase_cible_condens:\n",
    "                #Is the source equal to the end of the target?\n",
    "                return phrase_cible_condens[len(phrase_cible_condens)-len(phrase_source_condens):len(phrase_cible_condens)]==phrase_source_condens\n",
    "            else:\n",
    "                #Is the target equal to the end of the source?\n",
    "                return phrase_source_condens[len(phrase_source_condens)-len(phrase_cible_condens):len(phrase_source_condens)]==phrase_cible_condens\n",
    "        #Cas bleu ajout unilatéral\n",
    "        elif (phrase_source[\"couleur\"]==\"blue\") and (phrase_cible[\"couleur\"]==\"cyan\"):\n",
    "            return len(phrase_source[\"text\"])>10\n",
    "            \n",
    "        elif (phrase_source[\"couleur\"]==\"cyan\") and (phrase_cible[\"couleur\"]==\"blue\"):\n",
    "            return len(phrase_cible[\"text\"])>10\n",
    "    #else: cas vert vert normalement ou bleu sans modif sur le début de phrase\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5bccf1e1-2483-495f-817c-b9ded974b051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajout_last_or_first(paire_parag):\n",
    "    parag_source=[element for element in paire_parag[0] if ((len(element['text'])>0 or element[\"couleur\"] in [\"yellow\",\"red\"]) and element['couleur']!=\"black\")]\n",
    "    parag_cible=[element for element in paire_parag[1] if  ((len(element['text'])>0 or element[\"couleur\"] in [\"yellow\",\"red\"]) and element['couleur']!=\"black\")]\n",
    "    is_last=(parag_source[-1][\"couleur\"] in [\"yellow\",\"red\",\"blue\"]) or (parag_cible[-1][\"couleur\"] in [\"yellow\",\"red\",\"blue\"])\n",
    "    is_first=first_is_problem(parag_source[0],parag_cible[0])\n",
    "    if is_last:\n",
    "        is_last=last_is_problem(parag_source[-1],parag_cible[-1])\n",
    "    return is_first or is_last\n",
    "#c'est ok quand faux est renvoyé, donc quand les deux sont à false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1987ee-ecac-4cab-90df-58efda6cc294",
   "metadata": {},
   "source": [
    "### Filtre: Vérif balise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "43a37521-f983-49cb-9755-58c1034c7ca3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def verif_balise(liste_text_1, full_text_2):\n",
    "    baliseok=True\n",
    "    if len(liste_text_1)>0:\n",
    "        idx_debut=0\n",
    "        #We don't consider the tag at the beginning\n",
    "        while liste_text_1[idx_debut] in [\"[Table]\",\"[Figure]\",\"[Equation]\"]:\n",
    "            idx_debut+=1\n",
    "        idx_fin=len(liste_text_1)\n",
    "        #We don't consider the tags at the end\n",
    "        while liste_text_1[idx_fin-1] in [\"[Table]\",\"[Figure]\",\"[Equation]\"]:\n",
    "            idx_fin-=1\n",
    "        \n",
    "        cropped_liste_text_1=liste_text_1[idx_debut:idx_fin]\n",
    "        \n",
    "        #After the tags at the beginning, does the paragraph start correctly?\n",
    "        if idx_debut!=0:\n",
    "            baliseok = baliseok and not(check_incorrect_beginning(cropped_liste_text_1[0]))\n",
    "        #Before the tags at the end, does the paragraph end correctly\n",
    "        if idx_fin!=len(liste_text_1):\n",
    "            baliseok = baliseok and not(check_incorrect_ending(cropped_liste_text_1[-1]))\n",
    "        if not baliseok:\n",
    "            return baliseok\n",
    "        else:\n",
    "            idx_balise=0\n",
    "            #Was some text incorrectly replaced by a tag?\n",
    "            while idx_balise<len(cropped_liste_text_1):\n",
    "                if cropped_liste_text_1[idx_balise] in [\"[Table]\",\"[Figure]\",\"[Equation]\"]:\n",
    "                    new_tag_no_replace= (cropped_liste_text_1[idx_balise-1]+cropped_liste_text_1[idx_balise+1] in enlever_espaces(full_text_2))\n",
    "                    no_change= (cropped_liste_text_1[idx_balise-1]+cropped_liste_text_1[idx_balise]+cropped_liste_text_1[idx_balise+1] in enlever_espaces(full_text_2))\n",
    "                    baliseok=baliseok and (new_tag_no_replace or no_change)\n",
    "                idx_balise+=1\n",
    "    return baliseok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e8581a2b-ac8a-4798-a43d-06be56e1d6c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def balise_ok(parag): \n",
    "    parag_source=[phrase[\"text\"] for phrase in parag[0] if phrase[\"couleur\"]!=\"black\"]\n",
    "    parag_cible=[phrase[\"text\"] for phrase in parag[1] if phrase[\"couleur\"]!=\"black\"]\n",
    "\n",
    "    text_source,text_cible=recollage_parag_nocolor(parag_source,parag_cible)\n",
    "    liste_text_source=text_source.split(\" \")\n",
    "    liste_text_cible=text_cible.split(\" \")\n",
    "    \n",
    "    baliseok=True\n",
    "    if len(liste_text_source)>0:\n",
    "        baliseok= baliseok and verif_balise(liste_text_source, text_cible)\n",
    "    if len(parag_cible)>0:\n",
    "        baliseok= baliseok and verif_balise(liste_text_cible, text_source)\n",
    "    return baliseok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd51630-636e-4f04-90e5-24717fecb2e4",
   "metadata": {},
   "source": [
    "## Filtrage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c587ca1-46c1-42dd-bd8f-f807dd3df5d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_json=\"data/test/files_step5_complet/\"\n",
    "liste_articles=os.listdir(path_json)\n",
    "\n",
    "dico_all_parag_select={}\n",
    "parag_trop_petits=0\n",
    "\n",
    "for filename in liste_articles:\n",
    "    article=import_data(path_json,filename)\n",
    "    liste_section=get_list_paires_parag(article)\n",
    "      \n",
    "    liste_parag_valides=[]\n",
    "    for section in liste_section:\n",
    "        for parag in section:   \n",
    "            assez_grand=is_long_enough(parag)            \n",
    "            if assez_grand:\n",
    "                prct_modif_ok=respect_limit_modifs(parag)\n",
    "                if prct_modif_ok:\n",
    "                    equations_ok= not(contains_too_many_equations(parag,threshold=9))\n",
    "                    if equations_ok:\n",
    "                        #afficher_paire_parag(parag)\n",
    "                        last_first_ok=not(ajout_last_or_first(parag))\n",
    "                        if last_first_ok:\n",
    "                            baliseok=balise_ok(parag)\n",
    "                            if baliseok:\n",
    "                                liste_parag_valides.append(parag)                         \n",
    "                        \n",
    "            parag_trop_petits+=not(assez_grand)      \n",
    "    if len(liste_parag_valides)>0:\n",
    "        dico_all_parag_select[filename[:-6]]=liste_parag_valides    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1649885-704e-413b-a897-de3c6a453422",
   "metadata": {},
   "source": [
    "## Sauvegarde du mini-corpus de paragraphes entiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "484a98fc-e300-4b95-aa9b-6af03a7dbb08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fonction pour enlever les balises spécifiques\n",
    "def remove_tags_avec_espaces(chaine):\n",
    "    balises = [\" [Figure]\", \" [Equation]\", \" [Table]\"]\n",
    "    for balise in balises:\n",
    "        chaine = chaine.replace(balise, \"\")\n",
    "    balises = [\"[Figure] \", \"[Equation] \", \"[Table] \"]\n",
    "    for balise in balises:\n",
    "        chaine = chaine.replace(balise, \"\")\n",
    "    balises = [\"[Figure]\", \"[Equation]\", \"[Table]\"]\n",
    "    for balise in balises:\n",
    "        chaine = chaine.replace(balise, \"\")\n",
    "    return chaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc657f23-9b6d-4221-8775-9e490950d713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "liste_elargie=liste_test_exportafficher_paire_parag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025e260d-3bb4-4b2f-80ce-7195f4db9927",
   "metadata": {
    "tags": []
   },
   "source": [
    "**<span style=\"color: #FF0040\"> Faire attention a tout recoller correctement (double espaces, etc)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "766255f4-7a22-41f0-9fc7-5927565080a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16644 articles.\n",
      "48009 paragraphs.\n"
     ]
    }
   ],
   "source": [
    "liste_test_export=list(dico_all_parag_select.keys())\n",
    "print(len(liste_test_export),\"articles.\")\n",
    "nb_parag=sum( len(dico_all_parag_select[filename]) for filename in liste_test_export)\n",
    "print(nb_parag,\"paragraphs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dcaa622d-f82b-4081-b180-9f3c529ca981",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18410"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(liste_elargie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86d77a38-7435-4f19-bcbb-f403dcedbeae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "liste_diff=[article for article in liste_elargie if article not in liste_test_export]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "939f885a-3850-4cb6-b542-3bbfb8ef71ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1796"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(liste_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e343c2f-29cc-4945-9c78-f2a424cb16bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraphe source:\n",
      "\u001b[30m10|44-44|\u001b[0m\u001b[32mCartPole (Barto, Sutton, and Anderson, 1983)\u001b[0m\n",
      "\u001b[30m10|66-66|\u001b[0m\u001b[32mWe use the “swingup sparse” variant as implemented in Tassa et al.\u001b[0m\n",
      "\u001b[30m10|98-98|30.61 0.0\u001b[0m\u001b[36mIn this sparse reward version of the environment, the agent receives\u001b[0m\u001b[34mzero reward unless | x | < 0 .\u001b[0m\u001b[36m\u001b[0m\n",
      "\u001b[30m10|21-21|100.0 0\u001b[0m\u001b[33m25 and cos( θ ) > 0 .\u001b[0m\n",
      "\u001b[30m10|48-48|100.0 0\u001b[0m\u001b[33m995 , for the cart location x and pole angle θ .\u001b[0m\n",
      "\u001b[30m10|92-92|100.0 0\u001b[0m\u001b[33mAll episodes run for 1000 steps, and observations are 5 -dimensional continuous observation.\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m10|44-44|\u001b[0m\u001b[32mCartPole (Barto, Sutton, and Anderson, 1983)\u001b[0m\n",
      "\u001b[30m10|66-66|\u001b[0m\u001b[32mWe use the “swingup sparse” variant as implemented in Tassa et al.\u001b[0m\n",
      "\u001b[30m10|68-68|30.61 0.0\u001b[0m\u001b[36mIn this sparse reward version of the environment, the agent receives\u001b[0m\n",
      "\u001b[30m-2|0-0|100.0 0\u001b[0m\u001b[31m\u001b[0m\n",
      "\u001b[30m-2|0-0|100.0 0\u001b[0m\u001b[31m\u001b[0m\n",
      "\u001b[30m-2|0-0|100.0 0\u001b[0m\u001b[31m\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m4|56-56|\u001b[0m\u001b[32mHRL frameworks can be categorized as either zaz (cid:48)\u001b[0m\n",
      "\u001b[30m4|67-67|\u001b[0m\u001b[32me.g., (Ha & Schmidhuber, 2018; Hafner et al., 2019) or shs (cid:48)\u001b[0m\n",
      "\u001b[30m4|28-28|\u001b[0m\u001b[32me.g., (Sharma et al., 2019).\u001b[0m\n",
      "\u001b[30m4|124-124|\u001b[0m\u001b[32mThe similar network structures are used for the baselines; implementation details of the baselines also can be found in A.6.\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m6|56-56|\u001b[0m\u001b[32mHRL frameworks can be categorized as either zaz (cid:48)\u001b[0m\n",
      "\u001b[30m6|67-67|\u001b[0m\u001b[32me.g., (Ha & Schmidhuber, 2018; Hafner et al., 2019) or shs (cid:48)\u001b[0m\n",
      "\u001b[30m6|28-28|\u001b[0m\u001b[32me.g., (Sharma et al., 2019).\u001b[0m\n",
      "\u001b[30m6|124-124|\u001b[0m\u001b[32mThe similar network structures are used for the baselines; implementation details of the baselines also can be found in A.6.\u001b[0m\n",
      "\u001b[30m6|79-79|0 100.0\u001b[0m\u001b[31mTable 1 summarizes the different features of the models with the related works.\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m7|184-184|\u001b[0m\u001b[32mIn our experiments, we demonstrate that MISA achieves signiﬁcantly better performance on various environments of the D4RL (Fu et al., 2020) benchmark than the state-of-the-art methods.\u001b[0m\n",
      "\u001b[30m7|116-116|\u001b[0m\u001b[32mAdditional ablation studies, visualizations, and limitations are discussed to better understand the proposed method.\u001b[0m\n",
      "\u001b[30m7|43-43|100.0 0\u001b[0m\u001b[33mOur code will be released upon publication.\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m7|184-184|\u001b[0m\u001b[32mIn our experiments, we demonstrate that MISA achieves signiﬁcantly better performance on various environments of the D4RL (Fu et al., 2020) benchmark than the state-of-the-art methods.\u001b[0m\n",
      "\u001b[30m7|116-116|\u001b[0m\u001b[32mAdditional ablation studies, visualizations, and limitations are discussed to better understand the proposed method.\u001b[0m\n",
      "\u001b[30m-2|0-0|100.0 0\u001b[0m\u001b[31m\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m1|169-169|0.59 1.75\u001b[0m\u001b[36mHowever, these results do not generalize to residual ﬂows (Rezende \u001b[0m\u001b[34m&\u001b[0m\u001b[36m Mohamed, 2015; Van Den Berg et al., 2018; Behrmann et al., 2019; Chen et al., 2019) for two reasons.\u001b[0m\n",
      "\u001b[30m1|196-196|\u001b[0m\u001b[32mFirst, the approximation theory for normalizing ﬂows analyzes how well they can transform between distributions , rather than their ability to approximate a target function in the function space .\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m2|171-171|0.59 1.75\u001b[0m\u001b[36mHowever, these results do not generalize to residual ﬂows (Rezende \u001b[0m\u001b[34mand\u001b[0m\u001b[36m Mohamed, 2015; Van Den Berg et al., 2018; Behrmann et al., 2019; Chen et al., 2019) for two reasons.\u001b[0m\n",
      "\u001b[30m4|196-196|\u001b[0m\u001b[32mFirst, the approximation theory for normalizing ﬂows analyzes how well they can transform between distributions , rather than their ability to approximate a target function in the function space .\u001b[0m\n",
      "\u001b[30m4|212-212|0 100.0\u001b[0m\u001b[31mDespite that L p universality in the function space may lead to distributional universality for triangular ﬂows (Teshima et al., 2020), there is no similar results for non-triangular ﬂows including residual ﬂows.\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m0|200-200|\u001b[0m\u001b[32mA thank you is owed to Alice Zheng and Amanda Casari whose 2018 book “Feature Engineering for Machine Learning” served as a helpful reference as I began to explore the practice of feature engineering.\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m0|200-200|\u001b[0m\u001b[32mA thank you is owed to Alice Zheng and Amanda Casari whose 2018 book “Feature Engineering for Machine Learning” served as a helpful reference as I began to explore the practice of feature engineering.\u001b[0m\n",
      "\u001b[30m0|82-82|0 100.0\u001b[0m\u001b[31mThanks to Stack Overﬂow, Python, PyPI, GitHub, Colaboratory, Anaconda and Jupyter.\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m3|111-111|6.31 11.86\u001b[0m\u001b[36mMMM2) are too \u001b[0m\u001b[34mhard\u001b[0m\u001b[36m for both DPO and IPPO to win, so we use episode reward as the metric to show \u001b[0m\u001b[34mthe\u001b[0m\u001b[36m difference.\u001b[0m\n",
      "\u001b[30m3|129-129|76.74 36.17\u001b[0m\u001b[33mDPO performs better than IPPO on 2s3z, 8m, 27m_vs_30m and MMM2 and obtains better performance at the end of the training on 3s5z.\u001b[0m\n",
      "\u001b[30m3|209-209|\u001b[0m\u001b[32mWe need to argue that though we have controlled the network architectures of DPO and IPPO to be the same, in our experiments each agent has its individual parameters which increases the difficulty of training.\u001b[0m\n",
      "\u001b[30m3|57-57|\u001b[0m\u001b[32mSo our results in SMAC may be different from other works.\u001b[0m\n",
      "\u001b[30m3|75-75|\u001b[0m\u001b[32mAlthough IPPO has been shown to perform well in SMAC (de Witt et al., 2020;\u001b[0m\n",
      "\u001b[30m3|229-229|1.31 0.0\u001b[0m\u001b[36mYu et al., 2021; Papoudakis et al., 2021), DPO can still outperform IPPO, which verifies the effectiveness of the practical algorithm of DPO in high-dimensional complex tasks and can also be\u001b[0m\u001b[34mthe\u001b[0m\u001b[36m evidence of our theoretical result.\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m3|118-118|6.31 11.86\u001b[0m\u001b[36mMMM2) are too \u001b[0m\u001b[34mdifficult\u001b[0m\u001b[36m for both DPO and IPPO to win, so we use episode reward as the metric to show \u001b[0m\u001b[34mtheir\u001b[0m\u001b[36m difference.\u001b[0m\n",
      "\u001b[30m3|47-47|76.74 36.17\u001b[0m\u001b[31mDPO performs better than IPPO in all five maps.\u001b[0m\n",
      "\u001b[30m3|209-209|\u001b[0m\u001b[32mWe need to argue that though we have controlled the network architectures of DPO and IPPO to be the same, in our experiments each agent has its individual parameters which increases the difficulty of training.\u001b[0m\n",
      "\u001b[30m3|57-57|\u001b[0m\u001b[32mSo our results in SMAC may be different from other works.\u001b[0m\n",
      "\u001b[30m4|75-75|\u001b[0m\u001b[32mAlthough IPPO has been shown to perform well in SMAC (de Witt et al., 2020;\u001b[0m\n",
      "\u001b[30m4|226-226|1.31 0.0\u001b[0m\u001b[36mYu et al., 2021; Papoudakis et al., 2021), DPO can still outperform IPPO, which verifies the effectiveness of the practical algorithm of DPO in high-dimensional complex tasks and can also be evidence of our theoretical result.\u001b[0m\n",
      "\u001b[30m4|107-107|0 100.0\u001b[0m\u001b[31mAgain, the better performance of DPO in 27m_vs_30m shows its good scalability in the task with many agents.\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m5|117-117|\u001b[0m\u001b[32mTest Details We run experiments using Python 3.9 on jupyter-notebook, on MacBook Air (M1, 2020) running macOS 12.5.1.\u001b[0m\n",
      "\u001b[30m5|63-63|\u001b[0m\u001b[32mTime of execution is measured using the time package in Python.\u001b[0m\n",
      "\u001b[30m5|65-65|\u001b[0m\u001b[32mFor all tests, we take initial point to be the all-one vector z \n",
      "\u001b[0m\n",
      "\u001b[30m5|20-20|\u001b[0m\u001b[32m= ( 1, · · · , 1 ) .\u001b[0m\n",
      "\u001b[30m5|92-92|\u001b[0m\u001b[32mWe denote η to be the step size and the termination criteria is the residual (operator norm)\u001b[0m\n",
      "\u001b[30m5|21-21|\u001b[0m\u001b[32m|| F ( z t ) || ≤ ε .\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m5|117-117|\u001b[0m\u001b[32mTest Details We run experiments using Python 3.9 on jupyter-notebook, on MacBook Air (M1, 2020) running macOS 12.5.1.\u001b[0m\n",
      "\u001b[30m5|63-63|\u001b[0m\u001b[32mTime of execution is measured using the time package in Python.\u001b[0m\n",
      "\u001b[30m5|65-65|\u001b[0m\u001b[32mFor all tests, we take initial point to be the all-one vector z \n",
      "\u001b[0m\n",
      "\u001b[30m5|20-20|\u001b[0m\u001b[32m= ( 1, · · · , 1 ) .\u001b[0m\n",
      "\u001b[30m5|92-92|\u001b[0m\u001b[32mWe denote η to be the step size and the termination criteria is the residual (operator norm)\u001b[0m\n",
      "\u001b[30m5|21-21|\u001b[0m\u001b[32m|| F ( z t ) || ≤ ε .\u001b[0m\n",
      "\u001b[30m5|52-52|0 100.0\u001b[0m\u001b[31mThe code can be found in the Supplementary Material.\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m10|176-176|\u001b[0m\u001b[32mD Y HPO still performs better than all the other methods, we believe most of the methods converge toa good solution and the differences in the final performance are negligible.\u001b[0m\n",
      "\u001b[30m10|359-359|10.31 0.0\u001b[0m\u001b[36mFor the extended results,related to the performance of all methods on a dataset level over time, we refer the reader to theplots in Appendix B. Additionally, in Figure 5 (right), we provide the critical difference diagramsfor LCBench that present the ranks and the statistical difference of all methods halfway through\u001b[0m\u001b[34mtheoptimization procedure, and in\u001b[0m\u001b[36m the\u001b[0m\u001b[34mend.\u001b[0m\u001b[36m\u001b[0m\n",
      "\u001b[30m10|147-147|100.0 0\u001b[0m\u001b[33mAs it can be seen, D Y HPO has a better rank with a significantmargin with only half of the budget used and it retains the advantage until the end.\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m9|176-176|\u001b[0m\u001b[32mD Y HPO still performs better than all the other methods, we believe most of the methods converge toa good solution and the differences in the final performance are negligible.\u001b[0m\n",
      "\u001b[30m9|322-322|10.31 0.0\u001b[0m\u001b[36mFor the extended results,related to the performance of all methods on a dataset level over time, we refer the reader to theplots in Appendix B. Additionally, in Figure 5 (right), we provide the critical difference diagramsfor LCBench that present the ranks and the statistical difference of all methods halfway through the\u001b[0m\n",
      "\u001b[30m-2|0-0|100.0 0\u001b[0m\u001b[31m\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m11|158-158|\u001b[0m\u001b[32mA phenomenon frequently appearing in VAEs is posterior collapse, i.e., the posterior distribution (produced by an encoder) is close to the prior distribution.\u001b[0m\n",
      "\u001b[30m11|63-63|\u001b[0m\u001b[32mThis leads to a reduced expressivity of the VAE’s latent space.\u001b[0m\n",
      "\u001b[30m11|29-29|\u001b[0m\u001b[32mTo tackle this, Kingma et al.\u001b[0m\n",
      "\u001b[30m11|114-114|\u001b[0m\u001b[32m[8] proposed to constrain the KL divergence such that it is only active if the KL divergence is above a threshold.\u001b[0m\n",
      "\u001b[30m11|113-113|11.5 11.5\u001b[0m\u001b[36mOther works used KL annealing \u001b[0m\u001b[34m[31, 32]\u001b[0m\u001b[36m or constrained the posterior to have a minimum distance to the prior \u001b[0m\u001b[34m[33].\u001b[0m\u001b[36m\u001b[0m\n",
      "\u001b[30m11|12-12|\u001b[0m\u001b[32mLucas et al.\u001b[0m\n",
      "\u001b[30m11|103-103|\u001b[0m\u001b[32m[13] deﬁned the ( ǫ, δ ) − posterior collapse in order to reliably quantify posterior collapse in VAEs.\u001b[0m\n",
      "\u001b[30m11|161-161|100.0 0\u001b[0m\u001b[33mThey used a controlled training setting where the only source of stochasticity is the sampling of the reparameterization trick to investigate posterior collapse.\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m13|158-158|\u001b[0m\u001b[32mA phenomenon frequently appearing in VAEs is posterior collapse, i.e., the posterior distribution (produced by an encoder) is close to the prior distribution.\u001b[0m\n",
      "\u001b[30m13|63-63|\u001b[0m\u001b[32mThis leads to a reduced expressivity of the VAE’s latent space.\u001b[0m\n",
      "\u001b[30m13|29-29|\u001b[0m\u001b[32mTo tackle this, Kingma et al.\u001b[0m\n",
      "\u001b[30m13|114-114|\u001b[0m\u001b[32m[8] proposed to constrain the KL divergence such that it is only active if the KL divergence is above a threshold.\u001b[0m\n",
      "\u001b[30m13|113-113|11.5 11.5\u001b[0m\u001b[36mOther works used KL annealing \u001b[0m\u001b[34m[35, 36]\u001b[0m\u001b[36m or constrained the posterior to have a minimum distance to the prior \u001b[0m\u001b[34m[37].\u001b[0m\u001b[36m\u001b[0m\n",
      "\u001b[30m13|12-12|\u001b[0m\u001b[32mLucas et al.\u001b[0m\n",
      "\u001b[30m13|103-103|\u001b[0m\u001b[32m[13] deﬁned the ( ǫ, δ ) − posterior collapse in order to reliably quantify posterior collapse in VAEs.\u001b[0m\n",
      "\u001b[30m-2|0-0|100.0 0\u001b[0m\u001b[31m\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m1|42-42|\u001b[0m\u001b[32mWhat is exactly the likelihood of a image?\u001b[0m\n",
      "\u001b[30m1|108-108|7.41 10.71\u001b[0m\u001b[36mWe should \u001b[0m\u001b[34mbe clear\u001b[0m\u001b[36m that the predictive likelihood of a ﬂow is the joint probability of all the image pixels.\u001b[0m\n",
      "\u001b[30m1|110-110|\u001b[0m\u001b[32mThere is no doubt that ﬂows, trained by maximizing its likelihood, could generate impressive synthesized data.\u001b[0m\n",
      "\u001b[30m1|141-141|2.84 22.16\u001b[0m\u001b[36mThere seem to be no problem that in terms of image generation, we expect that every single generated pixel in a image is the most likely \u001b[0m\u001b[34mone.\u001b[0m\u001b[36m\u001b[0m\n",
      "\u001b[30m1|112-112|\u001b[0m\u001b[32mHowever, the likelihood is explicitly modeled on pixels, so can be easily inﬂuenced by pixel-level modiﬁcations.\u001b[0m\n",
      "\u001b[30m1|99-99|\u001b[0m\u001b[32mImages’ likelihoods signiﬁcantly decrease even small noises are added to the pixels of backgrounds.\u001b[0m\n",
      "\u001b[30m1|161-161|\u001b[0m\u001b[32mFor downstream tasks that need some “likelihood” to indicate the object in an image is a cat, rather than a car, the pixels of backgrounds are almost irrelevant.\u001b[0m\n",
      "\u001b[30m1|152-152|\u001b[0m\u001b[32mThis drive us to think that we may need to model likelihood in some kind of semantic space or with some “perceptual” metrics, rather than on raw pixels.\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m3|42-42|\u001b[0m\u001b[32mWhat is exactly the likelihood of a image?\u001b[0m\n",
      "\u001b[30m3|112-112|7.41 10.71\u001b[0m\u001b[36mWe should \u001b[0m\u001b[34mkeep in mind\u001b[0m\u001b[36m that the predictive likelihood of a ﬂow is the joint probability of all the image pixels.\u001b[0m\n",
      "\u001b[30m3|110-110|\u001b[0m\u001b[32mThere is no doubt that ﬂows, trained by maximizing its likelihood, could generate impressive synthesized data.\u001b[0m\n",
      "\u001b[30m3|176-176|2.84 22.16\u001b[0m\u001b[36mThere seem to be no problem that in terms of image generation, we expect that every single generated pixel in a image is the most likely \u001b[0m\u001b[34mone (hinging on its contextual pixels).\u001b[0m\u001b[36m\u001b[0m\n",
      "\u001b[30m3|112-112|\u001b[0m\u001b[32mHowever, the likelihood is explicitly modeled on pixels, so can be easily inﬂuenced by pixel-level modiﬁcations.\u001b[0m\n",
      "\u001b[30m3|99-99|\u001b[0m\u001b[32mImages’ likelihoods signiﬁcantly decrease even small noises are added to the pixels of backgrounds.\u001b[0m\n",
      "\u001b[30m3|161-161|\u001b[0m\u001b[32mFor downstream tasks that need some “likelihood” to indicate the object in an image is a cat, rather than a car, the pixels of backgrounds are almost irrelevant.\u001b[0m\n",
      "\u001b[30m3|152-152|\u001b[0m\u001b[32mThis drive us to think that we may need to model likelihood in some kind of semantic space or with some “perceptual” metrics, rather than on raw pixels.\u001b[0m\n",
      "\u001b[30m3|157-157|0 100.0\u001b[0m\u001b[31mOne promising direction is to deﬁne likelihood of an images on its high-level representation, and successful examples are (Lee, 2018; Nilesh A. Ahuja, 2019).\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m8|334-334|\u001b[0m\u001b[32mWhile in our results we focus on one-hidden layer generators and linear discriminators, our theory is based on analyzing a general class of min-max optimization problems which can be used to study a much broader class of generators and discriminators potentially including deep generators and deep random feature-based discriminators.\u001b[0m\n",
      "\u001b[30m8|224-224|\u001b[0m\u001b[32mA key component of our analysis is a novel connection to exponential stability of non-symmetric time varying dynamical systems in control theory which may have broader implications for theoretical analysis of GAN’s training.\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m8|334-334|\u001b[0m\u001b[32mWhile in our results we focus on one-hidden layer generators and linear discriminators, our theory is based on analyzing a general class of min-max optimization problems which can be used to study a much broader class of generators and discriminators potentially including deep generators and deep random feature-based discriminators.\u001b[0m\n",
      "\u001b[30m8|224-224|\u001b[0m\u001b[32mA key component of our analysis is a novel connection to exponential stability of non-symmetric time varying dynamical systems in control theory which may have broader implications for theoretical analysis of GAN’s training.\u001b[0m\n",
      "\u001b[30m8|142-142|0 100.0\u001b[0m\u001b[31mIdeas from control theory have also been used for understanding and improving training dynamics of GANs in (Xu et al., 2019; An et al., 2018).\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m4|115-115|\u001b[0m\u001b[32mTherefore, concentrated vectors are deﬁned through the concentration of any 1 -Lipschitz real scalar “observation”.\u001b[0m\n",
      "\u001b[30m4|89-89|\u001b[0m\u001b[32mOne of the most important examples of concentrated vectors are standard Gaussian vectors.\u001b[0m\n",
      "\u001b[30m4|45-45|\u001b[0m\u001b[32mPrecisely, we have the following proposition.\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m4|115-115|\u001b[0m\u001b[32mTherefore, concentrated vectors are deﬁned through the concentration of any 1 -Lipschitz real scalar “observation”.\u001b[0m\n",
      "\u001b[30m4|89-89|\u001b[0m\u001b[32mOne of the most important examples of concentrated vectors are standard Gaussian vectors.\u001b[0m\n",
      "\u001b[30m4|45-45|\u001b[0m\u001b[32mPrecisely, we have the following proposition.\u001b[0m\n",
      "\u001b[30m4|77-77|0 100.0\u001b[0m\u001b[31mSee (Ledoux, 2005)) for more examples such as uniform and Gamma distribution.\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m4|8-8|\u001b[0m\u001b[32mResults.\u001b[0m\n",
      "\u001b[30m4|33-33|\u001b[0m\u001b[32mWe report the results in Table 6.\u001b[0m\n",
      "\u001b[30m4|91-91|\u001b[0m\u001b[32mWe include previous best pre-trained V&L models and their V&L pre-training data and epochs.\u001b[0m\n",
      "\u001b[30m4|87-87|\u001b[0m\u001b[32mAs our model is based on BERT B ASE , we compare only with models based on BERT B ASE .\u001b[0m\n",
      "\u001b[30m4|52-52|\u001b[0m\u001b[32mThe models are grouped by their visual encoder type.\u001b[0m\n",
      "\u001b[30m4|112-112|100.0 0\u001b[0m\u001b[33mWe ﬁrst note that v2.0 mini-eval , “PE” denotes we follow similar prompt engineering as suggested in CLIP paper.\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m6|8-8|\u001b[0m\u001b[32mResults.\u001b[0m\n",
      "\u001b[30m6|33-33|\u001b[0m\u001b[32mWe report the results in Table 6.\u001b[0m\n",
      "\u001b[30m6|91-91|\u001b[0m\u001b[32mWe include previous best pre-trained V&L models and their V&L pre-training data and epochs.\u001b[0m\n",
      "\u001b[30m6|87-87|\u001b[0m\u001b[32mAs our model is based on BERT B ASE , we compare only with models based on BERT B ASE .\u001b[0m\n",
      "\u001b[30m6|52-52|\u001b[0m\u001b[32mThe models are grouped by their visual encoder type.\u001b[0m\n",
      "\u001b[30m-2|0-0|100.0 0\u001b[0m\u001b[31m\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m14|78-78|\u001b[0m\u001b[32mPath B attributes an input vector with both components above the target range.\u001b[0m\n",
      "\u001b[30m14|149-149|\u001b[0m\u001b[32mIG explains the zero result as the balance of two competing contributions, unlike BShap and Shap which consider the components to contribute equally.\u001b[0m\n",
      "\u001b[30m14|268-268|1.87 2.23\u001b[0m\u001b[36mDue to sharp features of the input-output landscape near the integration path, the IG attribution will undergo an abrupt reversal as the input crosses the x 1 = xboundary, even though neither the input nor baseline are near a decision boundary, nor in the target \u001b[0m\u001b[34mrange\u001b[0m\u001b[36m\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m16|78-78|\u001b[0m\u001b[32mPath B attributes an input vector with both components above the target range.\u001b[0m\n",
      "\u001b[30m16|149-149|\u001b[0m\u001b[32mIG explains the zero result as the balance of two competing contributions, unlike BShap and Shap which consider the components to contribute equally.\u001b[0m\n",
      "\u001b[30m16|269-269|1.87 2.23\u001b[0m\u001b[36mDue to sharp features of the input-output landscape near the integration path, the IG attribution will undergo an abrupt reversal as the input crosses the x 1 = xboundary, even though neither the input nor baseline are near a decision boundary, nor in the target \u001b[0m\u001b[34mrange.\u001b[0m\u001b[36m\u001b[0m\n",
      "\u001b[30m16|100-100|0 100.0\u001b[0m\u001b[31mIG attribution results can be arbitrarily affected by small sharp regions that fall across the path.\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m1|130-130|10.77 6.45\u001b[0m\u001b[36mIn our experiments, we report the mean of ten repetitions and we report two common \u001b[0m\u001b[34mmetrics suchas\u001b[0m\u001b[36m the regret and the average rank.\u001b[0m\n",
      "\u001b[30m1|136-136|0.0 0.0\u001b[0m\u001b[36mThe regret refers to the absolute difference between the score \u001b[0m\u001b[36mof the\u001b[0m\u001b[36m solution found by an optimizer compared to the best possible score.\u001b[0m\n",
      "\u001b[30m1|106-106|0.0 0.0\u001b[0m\u001b[36mIf we report the regret as \u001b[0m\u001b[36man aggregate\u001b[0m\u001b[36m result over multiple datasets, we report the mean over all regrets.\u001b[0m\n",
      "\u001b[30m1|87-87|0.0 0.0\u001b[0m\u001b[36mThe average rank is \u001b[0m\u001b[36mthe metric\u001b[0m\u001b[36m we use to aggregate rank results over different datasets.\u001b[0m\n",
      "\u001b[30m1|70-70|0.0 0.0\u001b[0m\u001b[36mWe provide further \u001b[0m\u001b[36mimplementation and\u001b[0m\u001b[36m training details in Appendix A.4.\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m1|124-124|10.77 6.45\u001b[0m\u001b[36mIn our experiments, we report the mean of ten repetitions and we report two common \u001b[0m\u001b[34mmetrics,\u001b[0m\u001b[36m the regret and the average rank.\u001b[0m\n",
      "\u001b[30m1|137-137|0.0 0.0\u001b[0m\u001b[36mThe regret refers to the absolute difference between the score \u001b[0m\u001b[36mof the\u001b[0m\u001b[36m solution found by an optimizer compared to the best possible score.\u001b[0m\n",
      "\u001b[30m1|107-107|0.0 0.0\u001b[0m\u001b[36mIf we report the regret as \u001b[0m\u001b[36man aggregate\u001b[0m\u001b[36m result over multiple datasets, we report the mean over all regrets.\u001b[0m\n",
      "\u001b[30m1|88-88|0.0 0.0\u001b[0m\u001b[36mThe average rank is \u001b[0m\u001b[36mthe metric\u001b[0m\u001b[36m we use to aggregate rank results over different datasets.\u001b[0m\n",
      "\u001b[30m1|71-71|0.0 0.0\u001b[0m\u001b[36mWe provide further \u001b[0m\u001b[36mimplementation and\u001b[0m\u001b[36m training details in Appendix A.4.\u001b[0m\n",
      "\u001b[30m1|52-52|0 100.0\u001b[0m\u001b[31mOur implementation of D Y HPO is publicly available.\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m4|122-122|\u001b[0m\u001b[32mJaakkola (2018) learn a self-explaining classiﬁer that takes as input a set of concepts extracted from the original input.\u001b[0m\n",
      "\u001b[30m4|179-179|7.82 4.07\u001b[0m\u001b[36m\u001b[0m\u001b[34mWhile they\u001b[0m\u001b[36m deﬁne a set of desiderata for what is an interpretable concept, \u001b[0m\u001b[34mthey\u001b[0m\u001b[36m simply represent extracted concepts as an encoding of the input learned with an auto-encoding loss.\u001b[0m\n",
      "\u001b[30m5|12-12|41.67 30.0\u001b[0m\u001b[36m\u001b[0m\u001b[34mQuint\u001b[0m\u001b[36m et al.\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\u001b[30m5|107-107|78.5 77.88\u001b[0m\u001b[33m(2018) extend a classic variational auto-encoder architecture with adifferentiable decision tree classiﬁer.\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m4|122-122|\u001b[0m\u001b[32mJaakkola (2018) learn a self-explaining classiﬁer that takes as input a set of concepts extracted from the original input.\u001b[0m\n",
      "\u001b[30m4|172-172|7.82 4.07\u001b[0m\u001b[36m\u001b[0m\u001b[34mThey\u001b[0m\u001b[36m deﬁne a set of desiderata for what is an interpretable concept, \u001b[0m\u001b[34mbut\u001b[0m\u001b[36m simply represent extracted concepts as an encoding of the input learned with an auto-encoding loss.\u001b[0m\n",
      "\u001b[30m4|10-10|41.67 30.0\u001b[0m\u001b[36m\u001b[0m\u001b[34mKim\u001b[0m\u001b[36m et al.\u001b[0m\n",
      "\u001b[30m4|49-49|0 100.0\u001b[0m\u001b[31mlearn concept activation vectors, and Zhou et al.\u001b[0m\n",
      "\u001b[30m4|104-104|78.5 77.88\u001b[0m\u001b[31m(2018) build on Bau et al. (2017) to propose a method that generates visual explanations of a classiﬁer.\u001b[0m\n",
      "\u001b[30m4|107-107|0 100.0\u001b[0m\u001b[31mHowever, in these models, the ﬁnal classiﬁer is already trained and ﬁxed while EDUCE is learned end-to-end.\u001b[0m\n",
      "\u001b[30m4|112-112|0 100.0\u001b[0m\u001b[31mMore importantly, these works need concepts to be predeﬁned from human annotations, while EDUCE is unsupervised.\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m17|134-134|0.0 0.0\u001b[0m\u001b[36mLastly, large language models have \u001b[0m\u001b[36mrecently opened\u001b[0m\u001b[36m the door for using explanations in \u001b[0m\u001b[36mfew-shot in-context\u001b[0m\u001b[36m learning (Brown et al., 2020).\u001b[0m\n",
      "\u001b[30m17|65-65|0.0 0.0\u001b[0m\u001b[36mWe represent this approach as Few-shot In-context \u001b[0m\u001b[36mLearning in\u001b[0m\u001b[36m Fig.\u001b[0m\n",
      "\u001b[30m17|269-269|0.0 0.0\u001b[0m\u001b[36mWe do not draw the dependencies between distinct data points in the context that \u001b[0m\u001b[36mwould be\u001b[0m\u001b[36m implied by the attention graph of Transformers, but instead represent the dependence of \u001b[0m\u001b[36meach data\u001b[0m\u001b[36m point on the unknown task τ , which \u001b[0m\u001b[36mmodels evidently\u001b[0m\u001b[36m do inference over at test time.\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m17|136-136|0.0 0.0\u001b[0m\u001b[36mLastly, large language models have \u001b[0m\u001b[36mrecently opened\u001b[0m\u001b[36m the door for using explanations in \u001b[0m\u001b[36mfew-shot in-context\u001b[0m\u001b[36m learning (Brown et al., 2020).\u001b[0m\n",
      "\u001b[30m17|66-66|0.0 0.0\u001b[0m\u001b[36mWe represent this approach as Few-shot In-context \u001b[0m\u001b[36mLearning in\u001b[0m\u001b[36m Fig.\u001b[0m\n",
      "\u001b[30m17|272-272|0.0 0.0\u001b[0m\u001b[36mWe do not draw the dependencies between distinct data points in the context that \u001b[0m\u001b[36mwould be\u001b[0m\u001b[36m implied by the attention graph of Transformers, but instead represent the dependence of \u001b[0m\u001b[36meach data\u001b[0m\u001b[36m point on the unknown task τ , which \u001b[0m\u001b[36mmodels evidently\u001b[0m\u001b[36m do inference over at test time.\u001b[0m\n",
      "\u001b[30m17|201-201|0 100.0\u001b[0m\u001b[31mInitial work in this direction suggests that models of a sufﬁciently large size (280B parameters) can learn from explanations provided in a few-shot in-context learning setting (Lampinen et al., 2022).\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m11|209-209|4.78 4.72\u001b[0m\u001b[36mSSL models that were trained \u001b[0m\u001b[36mwith a\u001b[0m\u001b[36m non-contrastive learning \u001b[0m\u001b[36mobjective (no\u001b[0m\u001b[36m negative examples), BarlowTwins \u001b[0m\u001b[34m[70],\u001b[0m\u001b[36m SwAV [9], and VICReg [5], as well as earlier \u001b[0m\u001b[36mSSL, non-Siamese\u001b[0m\u001b[36m models, Jigsaw \u001b[0m\u001b[34m[45],\u001b[0m\u001b[36m and Rotnet [21].\u001b[0m\n",
      "\u001b[30m11|212-212|8.02 8.41\u001b[0m\u001b[36mLast, we evaluate the largest available ViT \u001b[0m\u001b[34m[71],trained\u001b[0m\u001b[36m on the proprietary JFT-3B image classification dataset, which consists of approximately \u001b[0m\u001b[36mthree billion\u001b[0m\u001b[36m images belonging to approximately 30,000 classes \u001b[0m\u001b[34m[71].\u001b[0m\u001b[36m\u001b[0m\n",
      "\u001b[30m11|60-60|\u001b[0m\u001b[32mSee Table C.1 for further details regarding the models used.\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m6|212-212|4.78 4.72\u001b[0m\u001b[36mSSL models that were trained \u001b[0m\u001b[36mwith a\u001b[0m\u001b[36m non-contrastive learning \u001b[0m\u001b[36mobjective (no\u001b[0m\u001b[36m negative examples), BarlowTwins \u001b[0m\u001b[34m[71],\u001b[0m\u001b[36m SwAV [9], and VICReg [5], as well as earlier \u001b[0m\u001b[36mSSL, non-Siamese\u001b[0m\u001b[36m models, Jigsaw \u001b[0m\u001b[34m[46],\u001b[0m\u001b[36m and Rotnet [21].\u001b[0m\n",
      "\u001b[30m6|214-214|8.02 8.41\u001b[0m\u001b[36mLast, we evaluate the largest available ViT \u001b[0m\u001b[34m[72], trained\u001b[0m\u001b[36m on the proprietary JFT-3B image classification dataset, which consists of approximately \u001b[0m\u001b[36mthree billion\u001b[0m\u001b[36m images belonging to approximately 30,000 classes \u001b[0m\u001b[34m[72].\u001b[0m\u001b[36m\u001b[0m\n",
      "\u001b[30m6|60-60|\u001b[0m\u001b[32mSee Table C.1 for further details regarding the models used.\u001b[0m\n",
      "\u001b[30m6|133-133|0 100.0\u001b[0m\u001b[31mFigure C.1 shows the odd-one-out accuracy as a function of layer depth in a neural network for a few different network architectures.\u001b[0m\n",
      "\u001b[30m6|163-163|0 100.0\u001b[0m\u001b[31mLater layers generally perform better which is why we performed our analyses exclusively for the logits or penultimate/embedding layers of the models in Table C.1.\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m0|180-180|\u001b[0m\u001b[32mTo verify the effectiveness of our method in confidence estimation with limited labeled data, we start with evaluating on image classification and medical image segmentation tasks.\u001b[0m\n",
      "\u001b[30m0|77-77|\u001b[0m\u001b[32mActive learning is usually used as a follow-up task of confidence estimation.\u001b[0m\n",
      "\u001b[30m0|183-183|\u001b[0m\u001b[32mHere we implement active learning on image classification tasks to show that the highly uncertain samples picked up by our method will promote the learning process in a better manner.\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m0|180-180|\u001b[0m\u001b[32mTo verify the effectiveness of our method in confidence estimation with limited labeled data, we start with evaluating on image classification and medical image segmentation tasks.\u001b[0m\n",
      "\u001b[30m0|77-77|\u001b[0m\u001b[32mActive learning is usually used as a follow-up task of confidence estimation.\u001b[0m\n",
      "\u001b[30m0|183-183|\u001b[0m\u001b[32mHere we implement active learning on image classification tasks to show that the highly uncertain samples picked up by our method will promote the learning process in a better manner.\u001b[0m\n",
      "\u001b[30m0|76-76|0 100.0\u001b[0m\u001b[31mWe also evaluate our method on CIFAR10/ through anomaly detection in Append.\u001b[0m\n",
      "\u001b[30m0|4-4|0 100.0\u001b[0m\u001b[31mA.7.\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m1|126-126|\u001b[0m\u001b[32mTranscription Factors (TFs) as labels, genomic-sequence based TFBS prediction is a challenging multi-label classiﬁcation task.\u001b[0m\n",
      "\u001b[30m1|184-184|\u001b[0m\u001b[32mThere are two major biological mechanisms for TF binding: (1) sequence-speciﬁc binding patterns on genomes known as “motifs” and (2) interactions among TFs known as co-binding effects.\u001b[0m\n",
      "\u001b[30m1|125-125|\u001b[0m\u001b[32mIn this paper, we propose a novel deep architecture, the Prototype Matching Network (PMN) to mimic the TF binding mechanisms.\u001b[0m\n",
      "\u001b[30m1|124-124|\u001b[0m\u001b[32mOur PMN model automatically extracts prototypes (“motif”-like features) for each TF through a novel prototype-matching loss.\u001b[0m\n",
      "\u001b[30m1|151-151|55.63 58.64\u001b[0m\u001b[33mThrough a support set oflearned prototypes we use a LSTM to learn how TFs (labels) cooperate in deciding if multiple TFs will bind toa genomic segment.\u001b[0m\n",
      "\u001b[30m1|36-36|\u001b[0m\u001b[32mOn a reference TFBS dataset with 2 .\u001b[0m\n",
      "\u001b[30m1|119-119|5.04 0.0\u001b[0m\u001b[36m1 million genomic sequences, PMN signiﬁcantly outperforms\u001b[0m\u001b[34mstrong\u001b[0m\u001b[36m baselines and validates our design choices empirically.\u001b[0m\n",
      "\u001b[30m1|132-132|48.48 58.02\u001b[0m\u001b[33mTo our knowledge, this is the ﬁrst deep learning architecture to handle multi-label TFBS predictions while modeling TF interactions.\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m1|126-126|\u001b[0m\u001b[32mTranscription Factors (TFs) as labels, genomic-sequence based TFBS prediction is a challenging multi-label classiﬁcation task.\u001b[0m\n",
      "\u001b[30m1|184-184|\u001b[0m\u001b[32mThere are two major biological mechanisms for TF binding: (1) sequence-speciﬁc binding patterns on genomes known as “motifs” and (2) interactions among TFs known as co-binding effects.\u001b[0m\n",
      "\u001b[30m1|125-125|\u001b[0m\u001b[32mIn this paper, we propose a novel deep architecture, the Prototype Matching Network (PMN) to mimic the TF binding mechanisms.\u001b[0m\n",
      "\u001b[30m1|124-124|\u001b[0m\u001b[32mOur PMN model automatically extracts prototypes (“motif”-like features) for each TF through a novel prototype-matching loss.\u001b[0m\n",
      "\u001b[30m1|162-162|55.63 58.64\u001b[0m\u001b[31mBorrowing ideas from few-shot matching models, we use the notion of support set of prototypes and an LSTM to learn how TFs interact and bind to genomic sequences.\u001b[0m\n",
      "\u001b[30m1|36-36|\u001b[0m\u001b[32mOn a reference TFBS dataset with 2 .\u001b[0m\n",
      "\u001b[30m1|113-113|5.04 0.0\u001b[0m\u001b[36m1 million genomic sequences, PMN signiﬁcantly outperforms baselines and validates our design choices empirically.\u001b[0m\n",
      "\u001b[30m1|162-162|48.48 58.02\u001b[0m\u001b[31mTo our knowledge, this is the ﬁrst deep learning architecture that introduces prototype learning and considers TF-TF interactions for large scale TFBS prediction.\u001b[0m\n",
      "\u001b[30m1|91-91|0 100.0\u001b[0m\u001b[31mWe think such modeling strategies are more fundamental especially on datasets from biology.\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m9|104-104|\u001b[0m\u001b[32mA cause = lighting wherein there is a correlation between lighting condition lighting i and toy category\u001b[0m\n",
      "\u001b[30m9|1-1|\u001b[0m\u001b[32my\u001b[0m\n",
      "\u001b[30m9|138-138|\u001b[0m\u001b[32mi ; and Independent shift, A ind = azimuth that varies independently across domains, to generate our multi-attribute dataset light + azi .\u001b[0m\n",
      "\u001b[30m9|117-117|\u001b[0m\u001b[32mTraining domains have 0.9 and 0.95 spurious correlation with lighting whereas there is no correlation in test domain.\u001b[0m\n",
      "\u001b[30m9|42-42|30.95 29.27\u001b[0m\u001b[36mWe add 5% label noise in all \u001b[0m\u001b[34menvironments.\u001b[0m\u001b[36m\u001b[0m\n",
      "\u001b[30m9|87-87|100.0 0\u001b[0m\u001b[33mWe use ResNet-18 (pre-trained on ImageNet) for all settings and fine tune for our task.\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m9|104-104|\u001b[0m\u001b[32mA cause = lighting wherein there is a correlation between lighting condition lighting i and toy category\u001b[0m\n",
      "\u001b[30m9|1-1|\u001b[0m\u001b[32my\u001b[0m\n",
      "\u001b[30m9|138-138|\u001b[0m\u001b[32mi ; and Independent shift, A ind = azimuth that varies independently across domains, to generate our multi-attribute dataset light + azi .\u001b[0m\n",
      "\u001b[30m9|117-117|\u001b[0m\u001b[32mTraining domains have 0.9 and 0.95 spurious correlation with lighting whereas there is no correlation in test domain.\u001b[0m\n",
      "\u001b[30m9|41-41|30.95 29.27\u001b[0m\u001b[36mWe add 5% label noise in all \u001b[0m\u001b[34menvironments\u001b[0m\u001b[36m\u001b[0m\n",
      "\u001b[30m-2|0-0|100.0 0\u001b[0m\u001b[31m\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m3|12-12|\u001b[0m\u001b[32mZhang et al.\u001b[0m\n",
      "\u001b[30m3|278-278|\u001b[0m\u001b[32malso show how their attack can be applied in a secure multi-party ML setting, where multiple parties jointly train an ML model with their local data, and one of the parties wants to gain information about the data distribution of another party that participates in the training.\u001b[0m\n",
      "\u001b[30m3|18-18|\u001b[0m\u001b[32mMahloujifar et al.\u001b[0m\n",
      "\u001b[30m3|159-159|\u001b[0m\u001b[32m[21] show that data poisoning — which may happen in multi-party learning as well — can be used to increase the effectiveness of distribution inference attacks.\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m31|12-12|\u001b[0m\u001b[32mZhang et al.\u001b[0m\n",
      "\u001b[30m31|278-278|\u001b[0m\u001b[32malso show how their attack can be applied in a secure multi-party ML setting, where multiple parties jointly train an ML model with their local data, and one of the parties wants to gain information about the data distribution of another party that participates in the training.\u001b[0m\n",
      "\u001b[30m31|18-18|\u001b[0m\u001b[32mMahloujifar et al.\u001b[0m\n",
      "\u001b[30m31|159-159|\u001b[0m\u001b[32m[21] show that data poisoning — which may happen in multi-party learning as well — can be used to increase the effectiveness of distribution inference attacks.\u001b[0m\n",
      "\u001b[30m31|216-216|0 100.0\u001b[0m\u001b[31mTheir method introduces maliciously labeled data points into the training set that cause E [ Y 0 | X 0 ] to differ from E [ Y 1 | X 1 ] , leading to distribution leakage via the first source identified in this paper.\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m3|90-90|\u001b[0m\u001b[32mMany prior works [5, 6, 7, 8, 9, 10] try to mitigate this problem by handling OOD actions.\u001b[0m\n",
      "\u001b[30m3|136-136|\u001b[0m\u001b[32mTheydiscourage the policies to visit OOD actions by designing conservative value functions, or estimatingthe uncertainty of Q-functions.\u001b[0m\n",
      "\u001b[30m3|188-188|\u001b[0m\u001b[32mAlthough constraining the policy can implicitly mitigate the problemof state distributional shift, few works have adopted measures to explicitly handle OOD statesduring the training stage.\u001b[0m\n",
      "\u001b[30m3|166-166|\u001b[0m\u001b[32mIn this work, we propose the Pessimistic Ofﬂine Reinforcement Learning(PessORL) framework to explicitly limit the policy from visiting both unseen states and actions.\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m3|90-90|\u001b[0m\u001b[32mMany prior works [5, 6, 7, 8, 9, 10] try to mitigate this problem by handling OOD actions.\u001b[0m\n",
      "\u001b[30m3|136-136|\u001b[0m\u001b[32mTheydiscourage the policies to visit OOD actions by designing conservative value functions, or estimatingthe uncertainty of Q-functions.\u001b[0m\n",
      "\u001b[30m3|188-188|\u001b[0m\u001b[32mAlthough constraining the policy can implicitly mitigate the problemof state distributional shift, few works have adopted measures to explicitly handle OOD statesduring the training stage.\u001b[0m\n",
      "\u001b[30m3|166-166|\u001b[0m\u001b[32mIn this work, we propose the Pessimistic Ofﬂine Reinforcement Learning(PessORL) framework to explicitly limit the policy from visiting both unseen states and actions.\u001b[0m\n",
      "\u001b[30m3|122-122|0 100.0\u001b[0m\u001b[31mWerefer to the states or the actions that are not included in the training data as the unseen states or theunseen actions.\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m0|85-85|2.35 21.9\u001b[0m\u001b[36mIn this section, we present the \u001b[0m\u001b[34mAM\u001b[0m\u001b[36m models that we have designed using \u001b[0m\u001b[36mthis framework.\u001b[0m\u001b[36m\u001b[0m\n",
      "\u001b[30m0|127-127|0.0 0.0\u001b[0m\u001b[36mAll \u001b[0m\u001b[36mthese models\u001b[0m\u001b[36m are based on a pre-trained VAE that is used to provide initial \u001b[0m\u001b[36mestimates ˜\u001b[0m\u001b[36m z and predictions of \u001b[0m\u001b[36mx based\u001b[0m\u001b[36m on ˜ z .\u001b[0m\n",
      "\u001b[30m0|49-49|100.0 0\u001b[0m\u001b[33mThe proposed methods are represented in figure 1.\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m0|105-105|2.35 21.9\u001b[0m\u001b[36mIn this section, we present the \u001b[0m\u001b[34mauto-associative memory\u001b[0m\u001b[36m models that we have designed using \u001b[0m\u001b[36mthis framework.\u001b[0m\u001b[36m\u001b[0m\n",
      "\u001b[30m0|128-128|0.0 0.0\u001b[0m\u001b[36mAll \u001b[0m\u001b[36mthese models\u001b[0m\u001b[36m are based on a pre-trained VAE that is used to provide initial \u001b[0m\u001b[36mestimates ˜\u001b[0m\u001b[36m z and predictions of \u001b[0m\u001b[36mx based\u001b[0m\u001b[36m on ˜ z .\u001b[0m\n",
      "\u001b[30m-2|0-0|100.0 0\u001b[0m\u001b[31m\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m2|91-91|\u001b[0m\u001b[32mFurthermore the optimal values of K, L and λ depend on what dataset the experiment was run.\u001b[0m\n",
      "\u001b[30m2|75-75|\u001b[0m\u001b[32mFor the MNIST datasetthe authors used values of respectively 1, 7 and 0.05.\u001b[0m\n",
      "\u001b[30m2|87-87|\u001b[0m\u001b[32mFor the fMNIST dataset respectively 2, 4 and 0.05 were givenas optimal hyperparameters.\u001b[0m\n",
      "\u001b[30m2|108-108|\u001b[0m\u001b[32mAs described in Section 2.1.3, the authors used a sample-based method to estimate thecausal inﬂuence metric.\u001b[0m\n",
      "\u001b[30m2|140-140|\u001b[0m\u001b[32mFor all models trained to create the ﬁgures in the original report they used 25 samples for αand 100 samples for β ( N α = 25 , N β = 100 ).\u001b[0m\n",
      "\u001b[30m2|87-87|13.79 19.35\u001b[0m\u001b[36m\u001b[0m\u001b[34mThese values\u001b[0m\u001b[36m were found by the authors using the \u001b[0m\u001b[36mheuristic methoddescribed\u001b[0m\u001b[36m in Figure 1.\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m2|91-91|\u001b[0m\u001b[32mFurthermore the optimal values of K, L and λ depend on what dataset the experiment was run.\u001b[0m\n",
      "\u001b[30m2|75-75|\u001b[0m\u001b[32mFor the MNIST datasetthe authors used values of respectively 1, 7 and 0.05.\u001b[0m\n",
      "\u001b[30m2|87-87|\u001b[0m\u001b[32mFor the fMNIST dataset respectively 2, 4 and 0.05 were givenas optimal hyperparameters.\u001b[0m\n",
      "\u001b[30m2|108-108|\u001b[0m\u001b[32mAs described in Section 2.1.3, the authors used a sample-based method to estimate thecausal inﬂuence metric.\u001b[0m\n",
      "\u001b[30m2|140-140|\u001b[0m\u001b[32mFor all models trained to create the ﬁgures in the original report they used 25 samples for αand 100 samples for β ( N α = 25 , N β = 100 ).\u001b[0m\n",
      "\u001b[30m2|93-93|13.79 19.35\u001b[0m\u001b[36m\u001b[0m\u001b[34mThe α and β vakyes\u001b[0m\u001b[36m were found by the authors using the \u001b[0m\u001b[36mheuristicmethod described\u001b[0m\u001b[36m in Figure 1.\u001b[0m\n",
      "\u001b[30m2|59-59|0 100.0\u001b[0m\u001b[31mThe N α and N β values were not elaborated on in the paper.\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m4|108-108|\u001b[0m\u001b[32mGiven the small size of training data, we use data augmentation to properly estimate the network parameters.\u001b[0m\n",
      "\u001b[30m4|156-156|\u001b[0m\u001b[32mSpeciﬁcally, we reverse the input-output sequences and randomly extract intervals of variable size (with probability 0 . 5 ) from the full speech utterance.\u001b[0m\n",
      "\u001b[30m4|99-99|100.0 0\u001b[0m\u001b[33mThe source code can be download from: https://github.com/ravi-0841/adaptive_duration_modification .\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m4|108-108|\u001b[0m\u001b[32mGiven the small size of training data, we use data augmentation to properly estimate the network parameters.\u001b[0m\n",
      "\u001b[30m4|156-156|\u001b[0m\u001b[32mSpeciﬁcally, we reverse the input-output sequences and randomly extract intervals of variable size (with probability 0 . 5 ) from the full speech utterance.\u001b[0m\n",
      "\u001b[30m-2|0-0|100.0 0\u001b[0m\u001b[31m\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m4|69-69|\u001b[0m\u001b[32mLyapunov barrier functions that generalize despite model uncertainty.\u001b[0m\n",
      "\u001b[30m4|230-230|4.78 5.17\u001b[0m\u001b[36mWe demonstrate our approach in simulation on problems including car trajectory \u001b[0m\u001b[36mtracking, nonlinear\u001b[0m\u001b[36m control with obstacle avoidance, satellite rendezvous with safety \u001b[0m\u001b[34mconstraints\u001b[0m\u001b[36m and ﬂ ight control with a learned ground effect model.\u001b[0m\n",
      "\u001b[30m4|170-170|5.29 5.78\u001b[0m\u001b[36mSimulation \u001b[0m\u001b[36mresults show\u001b[0m\u001b[36m that our approach yields controllers that match or exceed the capabilities \u001b[0m\u001b[36mof robust\u001b[0m\u001b[36m MPC while reducing computational costs by an order of \u001b[0m\u001b[34mmagnitude\u001b[0m\u001b[36m\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m1|69-69|\u001b[0m\u001b[32mLyapunov barrier functions that generalize despite model uncertainty.\u001b[0m\n",
      "\u001b[30m1|232-232|4.78 5.17\u001b[0m\u001b[36mWe demonstrate our approach in simulation on problems including car trajectory \u001b[0m\u001b[36mtracking, nonlinear\u001b[0m\u001b[36m control with obstacle avoidance, satellite rendezvous with safety \u001b[0m\u001b[34mconstraints,\u001b[0m\u001b[36m and ﬂ ight control with a learned ground effect model.\u001b[0m\n",
      "\u001b[30m1|173-173|5.29 5.78\u001b[0m\u001b[36mSimulation \u001b[0m\u001b[36mresults show\u001b[0m\u001b[36m that our approach yields controllers that match or exceed the capabilities \u001b[0m\u001b[36mof robust\u001b[0m\u001b[36m MPC while reducing computational costs by an order of \u001b[0m\u001b[34mmagnitude.\u001b[0m\u001b[36m\u001b[0m\n",
      "\u001b[30m1|59-59|0 100.0\u001b[0m\u001b[31mWe provide source code at github.com/dawsonc/neural_clbf/ .\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m0|194-194|\u001b[0m\u001b[32mIn this section, we quantify the privacy ampliﬁcation by randomized post-processing in Algorithm 1,during iterations that do not access the sensitive differing data between neighboring datasets.\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m0|194-194|\u001b[0m\u001b[32mIn this section, we quantify the privacy ampliﬁcation by randomized post-processing in Algorithm 1,during iterations that do not access the sensitive differing data between neighboring datasets.\u001b[0m\n",
      "\u001b[30m0|111-111|0 100.0\u001b[0m\u001b[31mWethen combine it with Rényi DP composition during the remaining iterations to prove a convergingprivacy bound.\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m1|132-132|\u001b[0m\u001b[32mComparing with the baseline (Carlini et al., 2022), we find that a larger majority vote number leads to a better certified accuracy.\u001b[0m\n",
      "\u001b[30m1|182-182|\u001b[0m\u001b[32mIt verifies that DensePure indeed benefits the adversarial robustness and making a good approximation of the label with high density region requires a large number of voting samples.\u001b[0m\n",
      "\u001b[30m1|68-68|\u001b[0m\u001b[32mWe find that our certified accuracy will almost converge at r = 40 .\u001b[0m\n",
      "\u001b[30m1|40-40|\u001b[0m\u001b[32mThus, we set r = 40 for our experiments.\u001b[0m\n",
      "\u001b[30m1|51-51|\u001b[0m\u001b[32mThe results with other σ show the similar tendency.\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m1|132-132|\u001b[0m\u001b[32mComparing with the baseline (Carlini et al., 2022), we find that a larger majority vote number leads to a better certified accuracy.\u001b[0m\n",
      "\u001b[30m1|182-182|\u001b[0m\u001b[32mIt verifies that DensePure indeed benefits the adversarial robustness and making a good approximation of the label with high density region requires a large number of voting samples.\u001b[0m\n",
      "\u001b[30m1|68-68|\u001b[0m\u001b[32mWe find that our certified accuracy will almost converge at r = 40 .\u001b[0m\n",
      "\u001b[30m1|40-40|\u001b[0m\u001b[32mThus, we set r = 40 for our experiments.\u001b[0m\n",
      "\u001b[30m1|51-51|\u001b[0m\u001b[32mThe results with other σ show the similar tendency.\u001b[0m\n",
      "\u001b[30m1|89-89|0 100.0\u001b[0m\u001b[31mTo further improve the time efficency, we can use K -Consensus (Horv ´ ath et al., 2021).\u001b[0m\n",
      "\u001b[30m1|89-89|0 100.0\u001b[0m\u001b[31mIt accelerates the majority vote process by 45% ∼ 60% with a negligible performance drop.\u001b[0m\n",
      "\u001b[30m1|57-57|0 100.0\u001b[0m\u001b[31mThe experimental details and results are in Appendix D.8.\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m1|124-124|0.0 0.0\u001b[0m\u001b[36mMTL enables a straightforward joint training procedure to integrate transcript information on \u001b[0m\u001b[36mmultiple levels\u001b[0m\u001b[36m of granularity.\u001b[0m\n",
      "\u001b[30m1|174-174|0.0 0.0\u001b[0m\u001b[36mTreating word- and character-level transcription as two distinct tasks allows \u001b[0m\u001b[36mfor combining\u001b[0m\u001b[36m their losses in a parallel [22, 23, 29, 30] or hierarchical structure [14, 21, 25].\u001b[0m\n",
      "\u001b[30m1|149-149|0.0 0.0\u001b[0m\u001b[36m\u001b[0m\u001b[36mAugmenting the\u001b[0m\u001b[36m commonly-used CTC loss with an attention mechanism can help with aligning the predictions \u001b[0m\u001b[36mon both\u001b[0m\u001b[36m character- and word-level [4, 13, 23].\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m1|125-125|0.0 0.0\u001b[0m\u001b[36mMTL enables a straightforward joint training procedure to integrate transcript information on \u001b[0m\u001b[36mmultiple levels\u001b[0m\u001b[36m of granularity.\u001b[0m\n",
      "\u001b[30m1|175-175|0.0 0.0\u001b[0m\u001b[36mTreating word- and character-level transcription as two distinct tasks allows \u001b[0m\u001b[36mfor combining\u001b[0m\u001b[36m their losses in a parallel [22, 23, 29, 30] or hierarchical structure [14, 21, 25].\u001b[0m\n",
      "\u001b[30m1|151-151|0.0 0.0\u001b[0m\u001b[36m\u001b[0m\u001b[36mAugmenting the\u001b[0m\u001b[36m commonly-used CTC loss with an attention mechanism can help with aligning the predictions \u001b[0m\u001b[36mon both\u001b[0m\u001b[36m character- and word-level [4, 13, 23].\u001b[0m\n",
      "\u001b[30m1|54-54|0 100.0\u001b[0m\u001b[31mAll these MTL methods improve a standard CTC baseline.\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m1|148-148|\u001b[0m\u001b[32mMoreover, we compare DrNAS with DARTS and R-DARTS on 4 simpliﬁed space proposed in (Zela et al., 2020a) and record the endpoint dominant eigenvalue.\u001b[0m\n",
      "\u001b[30m1|85-85|\u001b[0m\u001b[32mThe ﬁrst space S1 contains 2 popular operators per edge based on DARTS search result.\u001b[0m\n",
      "\u001b[30m1|208-208|\u001b[0m\u001b[32mFor S2, S3, and S4, the operation sets are { 3 ×separable convolution , skip connection } , { 3 × 3 separable convolution , skip connection , zero } , and { 3 × 3 separable convolution , noise } respectively.\u001b[0m\n",
      "\u001b[30m1|52-52|0.0 25.71\u001b[0m\u001b[36mAs shown in Table 6, DrNAS consistently outperforms \u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m1|148-148|\u001b[0m\u001b[32mMoreover, we compare DrNAS with DARTS and R-DARTS on 4 simpliﬁed space proposed in (Zela et al., 2020a) and record the endpoint dominant eigenvalue.\u001b[0m\n",
      "\u001b[30m1|85-85|\u001b[0m\u001b[32mThe ﬁrst space S1 contains 2 popular operators per edge based on DARTS search result.\u001b[0m\n",
      "\u001b[30m1|208-208|\u001b[0m\u001b[32mFor S2, S3, and S4, the operation sets are { 3 ×separable convolution , skip connection } , { 3 × 3 separable convolution , skip connection , zero } , and { 3 × 3 separable convolution , noise } respectively.\u001b[0m\n",
      "\u001b[30m1|70-70|0.0 25.71\u001b[0m\u001b[36mAs shown in Table 6, DrNAS consistently outperforms \u001b[0m\u001b[34mDARTS and R-DARTS.\u001b[0m\u001b[36m\u001b[0m\n",
      "\u001b[30m1|83-83|0 100.0\u001b[0m\u001b[31mThe endpoint eigenvalues for DrNAS are 0.0392, 0.0390, 0.0286, 0.0389 respectively.\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m0|140-140|11.43 60.13\u001b[0m\u001b[33mThe latter assessor is trained solely on a dataset of  vocabulary test results of ESL learners [7] withoutusing any text readability labels.\u001b[0m\n",
      "\u001b[30m0|87-87|4.6 13.4\u001b[0m\u001b[36m\u001b[0m\u001b[34mThis\u001b[0m\u001b[36m assessor is solely based on vocabulary; hence, it cannot \u001b[0m\u001b[36mconsider textual\u001b[0m\u001b[36m contexts.\u001b[0m\n",
      "\u001b[30m0|171-171|28.07 26.79\u001b[0m\u001b[36mAlthough \u001b[0m\u001b[34mthis assessor\u001b[0m\u001b[36m does not achieve the highest accuracy, its \u001b[0m\u001b[34mresult is highlyinterpretable\u001b[0m\u001b[36m because it \u001b[0m\u001b[34mshows\u001b[0m\u001b[36m which word in \u001b[0m\u001b[34ma\u001b[0m\u001b[36m text is difficult to what type of learner.\u001b[0m\n",
      "\u001b[30m0|201-201|10.95 17.81\u001b[0m\u001b[36mTo \u001b[0m\u001b[34massess,this\u001b[0m\u001b[36m assessor calculates the bag-of-words probability that the average ability test-taker knows all \u001b[0m\u001b[36mthe words\u001b[0m\u001b[36m in a given \u001b[0m\u001b[34mtext,\u001b[0m\u001b[36m and \u001b[0m\u001b[34mregard\u001b[0m\u001b[36m its negative logarithm as the readability of the text.\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m0|311-311|11.43 60.13\u001b[0m\u001b[31mThe latter assessor is trained solely on a dataset of the vocabulary test results of ESL learners [7]; hence, although this assessor uses supervised learning from the viewpoint of machine-learning, it is categorized as an unsupervised readability assessor by [11] as it does not use any text readability labels.\u001b[0m\n",
      "\u001b[30m0|97-97|4.6 13.4\u001b[0m\u001b[36m\u001b[0m\u001b[34mNotably, this\u001b[0m\u001b[36m assessor is solely based on vocabulary; hence, it cannot \u001b[0m\u001b[36mconsider textual\u001b[0m\u001b[36m contexts.\u001b[0m\n",
      "\u001b[30m1|168-168|28.07 26.79\u001b[0m\u001b[36mAlthough \u001b[0m\u001b[34mit\u001b[0m\u001b[36m does not achieve the highest accuracy, its \u001b[0m\u001b[34mresults are highly interpretable\u001b[0m\u001b[36m because it \u001b[0m\u001b[34mcan show\u001b[0m\u001b[36m which word in \u001b[0m\u001b[34mthe\u001b[0m\u001b[36m text is difficult to what type of learner.\u001b[0m\n",
      "\u001b[30m2|219-219|10.95 17.81\u001b[0m\u001b[36mTo \u001b[0m\u001b[34mperform the assessment, this\u001b[0m\u001b[36m assessor calculates the bag-of-words probability that the average ability test-taker knows all \u001b[0m\u001b[36mthe words\u001b[0m\u001b[36m in a given \u001b[0m\u001b[34mtext\u001b[0m\u001b[36m and \u001b[0m\u001b[34mregards\u001b[0m\u001b[36m its negative logarithm as the readability of the text.\u001b[0m\n",
      "\u001b[30m2|46-46|0 100.0\u001b[0m\u001b[31mIn other words, this assessor is personalized.\u001b[0m\n",
      "\u001b[30m2|197-197|0 100.0\u001b[0m\u001b[31mAs will be explained later, it uses a parameter that can be interpreted to represent the ability of each language-learner who takes the test; thus, it considers the knowledge level of each learner.\u001b[0m\n",
      "\u001b[30m2|112-112|0 100.0\u001b[0m\u001b[31mAdditionally, the weights of different words are obtained by considering word frequencies from multiple corpora.\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m0|216-216|3.7 6.73\u001b[0m\u001b[36mHere we show that performance gains of local parallelism can be realized on real hardware, and that they are similar to or better than pipelined \u001b[0m\u001b[34mbackprop\u001b[0m\u001b[36m despite the increased computation needed for auxiliary losses.\u001b[0m\n",
      "\u001b[30m0|238-238|3.36 6.12\u001b[0m\u001b[36mWe train ResNet34, ResNet50 and ResNet101 (He et al., 2016) on the ImageNet dataset (Deng et al., 2009), and compare throughput (images per second) between chunked local parallelism and synchronous pipelined \u001b[0m\u001b[34mbackprop\u001b[0m\u001b[36m (Huang et al., 2019).\u001b[0m\n",
      "\u001b[30m0|96-96|8.33 42.48\u001b[0m\u001b[36mWe implement the models in TensorFlow (Abadi et al., 2016) and train them across 4 or 8 \u001b[0m\u001b[34mIPUs 1 .\u001b[0m\u001b[36m\u001b[0m\n",
      "\u001b[30m0|172-172|59.88 82.84\u001b[0m\u001b[33mNote that the baseline conﬁguration is restricted to pipeline parallelism, and hence is not optimized for overall throughput  which could be enhanced with data parallelism.\u001b[0m\n",
      "\u001b[30m0|155-155|5.81 14.12\u001b[0m\u001b[36mThe results in Table 1 show that chunked local parallelism can achieve similar or greater throughput  to pipelined \u001b[0m\u001b[34mbackprop,\u001b[0m\u001b[36m for the same local batch size.\u001b[0m\n",
      "\u001b[30m0|106-106|10.38 30.15\u001b[0m\u001b[36m\u001b[0m\u001b[34mThus\u001b[0m\u001b[36m local parallelism can enable similar hardware efﬁciency without necessitating \u001b[0m\u001b[34ma large\u001b[0m\u001b[36m minibatch size.\u001b[0m\n",
      "\u001b[30m0|128-128|\u001b[0m\u001b[32mIt is therefore amenable to a greater level of data parallelism before performance degradation due to a large global batch size.\u001b[0m\n",
      "\u001b[30m0|180-180|9.44 27.23\u001b[0m\u001b[36mThe difference in throughput between \u001b[0m\u001b[34mbackprop\u001b[0m\u001b[36m and local parallelism  is primarily due to the poor utilisation during the “ramp-up” and “ramp-down” phases of the pipelined \u001b[0m\u001b[34mbackprop.\u001b[0m\u001b[36m\u001b[0m\n",
      "\u001b[30m0|116-116|\u001b[0m\u001b[32mThis can be mitigated by running the pipeline in the steady state for more stages (compare rows 4 and 5 of Table 1).\u001b[0m\n",
      "\u001b[30m1|137-137|\u001b[0m\u001b[32mHowever, this results in the accumulation of gradients from a larger number of local batches, thus costing a larger effective batch size.\u001b[0m\n",
      "\u001b[30m1|157-157|4.46 4.46\u001b[0m\u001b[36mWith greedy local parallelism, updates can be applied asynchronously and the pipeline can be run in steady state indeﬁnitely, after an initial \u001b[0m\u001b[34mramp up\u001b[0m\u001b[36m phase.\u001b[0m\n",
      "\u001b[30m-2|0-0|0 100.0\u001b[0m\u001b[33m\u001b[0m\n",
      "\n",
      "Paragraphe cible:\n",
      "\u001b[30m0|223-223|3.7 6.73\u001b[0m\u001b[36mHere we show that performance gains of local parallelism can be realized on real hardware, and that they are similar to or better than pipelined \u001b[0m\u001b[34mbackpropagation\u001b[0m\u001b[36m despite the increased computation needed for auxiliary losses.\u001b[0m\n",
      "\u001b[30m0|245-245|3.36 6.12\u001b[0m\u001b[36mWe train ResNet34, ResNet50 and ResNet101 (He et al., 2016) on the ImageNet dataset (Deng et al., 2009), and compare throughput (images per second) between chunked local parallelism and synchronous pipelined \u001b[0m\u001b[34mbackpropagation\u001b[0m\u001b[36m (Huang et al., 2019).\u001b[0m\n",
      "\u001b[30m0|153-153|8.33 42.48\u001b[0m\u001b[36mWe implement the models in TensorFlow (Abadi et al., 2016) and train them across 4 or 8 \u001b[0m\u001b[34mIntelligence Processing Units (IPUs – see details in Appendix E).\u001b[0m\u001b[36m\u001b[0m\n",
      "\u001b[30m1|402-402|59.88 82.84\u001b[0m\u001b[31mNote that both local and pipeline conﬁgurations are not optimized for overall throughput LM: This feels weird becuase they are optimized for throughput – just only using a single smaller number of chips right? – they do not make use of data parallelism which could be applied identically in both cases. We use activation recomputation in the case of pipelined backprop (see discussion in Appendix D.3).\u001b[0m\n",
      "\u001b[30m1|170-170|5.81 14.12\u001b[0m\u001b[36mThe results in Table 1 show that chunked local parallelism can achieve similar or greater throughput \u001b[0m\u001b[34mcompared\u001b[0m\u001b[36m to pipelined \u001b[0m\u001b[34mbackpropagation,\u001b[0m\u001b[36m for the same local batch size.\u001b[0m\n",
      "\u001b[30m1|136-136|10.38 30.15\u001b[0m\u001b[36m\u001b[0m\u001b[34mThis provides evidence that\u001b[0m\u001b[36m local parallelism can enable similar hardware efﬁciency without necessitating \u001b[0m\u001b[34man increase of\u001b[0m\u001b[36m minibatch size.\u001b[0m\n",
      "\u001b[30m1|128-128|\u001b[0m\u001b[32mIt is therefore amenable to a greater level of data parallelism before performance degradation due to a large global batch size.\u001b[0m\n",
      "\u001b[30m1|224-224|9.44 27.23\u001b[0m\u001b[36mThe difference in throughput between \u001b[0m\u001b[34mbackpropagation\u001b[0m\u001b[36m and local parallelism \u001b[0m\u001b[34mwith the same local batch size\u001b[0m\u001b[36m is primarily due to the poor utilisation during the “ramp-up” and “ramp-down” phases of the pipelined \u001b[0m\u001b[34mbackpropagation.\u001b[0m\u001b[36m\u001b[0m\n",
      "\u001b[30m1|116-116|\u001b[0m\u001b[32mThis can be mitigated by running the pipeline in the steady state for more stages (compare rows 4 and 5 of Table 1).\u001b[0m\n",
      "\u001b[30m1|137-137|\u001b[0m\u001b[32mHowever, this results in the accumulation of gradients from a larger number of local batches, thus costing a larger effective batch size.\u001b[0m\n",
      "\u001b[30m1|157-157|4.46 4.46\u001b[0m\u001b[36mWith greedy local parallelism, updates can be applied asynchronously and the pipeline can be run in steady state indeﬁnitely, after an initial \u001b[0m\u001b[34mramp-up\u001b[0m\u001b[36m phase.\u001b[0m\n",
      "\u001b[30m1|80-80|0 100.0\u001b[0m\u001b[31mHardware utilization analysis and further discussion can be found in Appendix D.\u001b[0m\n",
      "----------------------------------------------------------------------\n",
      "Paragraphe source:\n",
      "\u001b[30m1|44-44|\u001b[0m\u001b[32mThis new task is illustrated in Figure 5(a).\u001b[0m\n",
      "\u001b[30m1|47-47|\u001b[0m\u001b[32mThe input consists of two images and an action.\u001b[0m\n",
      "\u001b[30m1|168-168|\u001b[0m"
     ]
    }
   ],
   "source": [
    "for filename in liste_diff:\n",
    "        idx_parag=0        \n",
    "        for parag in dico_all_parag_select[filename]:\n",
    "            parag=corrections_espaces_et_tirets(parag)\n",
    "            for phrase in parag[0]:\n",
    "                phrase[\"text\"]=remove_tags_avec_espaces(phrase[\"text\"])\n",
    "            for phrase in parag[1]:\n",
    "                phrase[\"text\"]=remove_tags_avec_espaces(phrase[\"text\"])\n",
    "        afficher_paire_parag(parag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d04cb0c7-30d2-49ec-8ca7-fed850517a88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def difference_tiret(chaine1, chaine2):\n",
    "    # Vérifie si les longueurs des chaînes diffèrent exactement de 1\n",
    "    if abs(len(chaine1) - len(chaine2)) != 1:\n",
    "        return False\n",
    "    \n",
    "    # Identifie la chaîne la plus courte et la plus longue\n",
    "    courte = min(chaine1, chaine2, key=len)\n",
    "    longue = max(chaine1, chaine2, key=len)\n",
    "\n",
    "    # Supprime tous les tirets des deux chaînes\n",
    "    chaine1_sans_tiret = chaine1.replace(\"-\", \"\")\n",
    "    chaine2_sans_tiret = chaine2.replace(\"-\", \"\")\n",
    "\n",
    "    # Vérifie si les chaînes sont identiques après suppression des tirets\n",
    "    if chaine1_sans_tiret == chaine2_sans_tiret:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89b76205-1adc-4152-8b88-52a21d5058c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def corrections_espaces_et_tirets(parag):\n",
    "    source=parag[0]\n",
    "    cible=parag[1]\n",
    "    not_end_source=True\n",
    "    not_end_cible=True\n",
    "    idx_source=0\n",
    "    idx_cible=0\n",
    "    while not_end_source and not_end_cible:\n",
    "        phrase_source=source[idx_source]['text']\n",
    "        phrase_cible=cible[idx_cible]['text']\n",
    "        if (source[idx_source]['couleur']=='cyan') and (cible[idx_cible]['couleur']=='cyan'):\n",
    "            if len(phrase_source)!=len(phrase_cible) and sont_egales_sans_espaces(phrase_source,phrase_cible):\n",
    "                if len(phrase_source)>len(phrase_cible):\n",
    "                    parag[1][idx_cible]['text']=source[idx_source]['text']\n",
    "                else:\n",
    "                    parag[0][idx_source]['text']=cible[idx_cible]['text']\n",
    "            idx_source+=1\n",
    "            idx_cible+=1\n",
    "        elif (source[idx_source]['couleur']=='blue') and (cible[idx_cible]['couleur']=='cyan'):\n",
    "            idx_source+=1\n",
    "        elif (source[idx_source]['couleur']=='cyan') and (cible[idx_cible]['couleur']=='blue'):\n",
    "            idx_cible+=1\n",
    "        elif (source[idx_source]['couleur']=='blue') and (cible[idx_cible]['couleur']=='blue'):\n",
    "            if difference_tiret(phrase_source,phrase_cible):\n",
    "                if len(phrase_source)>len(phrase_cible):\n",
    "                    parag[1][idx_cible]['text']=source[idx_source]['text']                    \n",
    "                else:\n",
    "                    parag[0][idx_source]['text']=cible[idx_cible]['text']                    \n",
    "                parag[1][idx_cible]['couleur']='cyan'\n",
    "                parag[0][idx_source]['couleur']='cyan'\n",
    "            idx_source+=1\n",
    "            idx_cible+=1\n",
    "        else:\n",
    "            #cas jr ou v \n",
    "            idx_source+=1\n",
    "            idx_cible+=1\n",
    "        if (idx_source==len(source)):\n",
    "            not_end_source=False\n",
    "        if (idx_cible==len(cible)):\n",
    "            not_end_cible=False\n",
    "    return parag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25afc0e6-eeca-47b7-8fdf-b79c68687c6a",
   "metadata": {},
   "source": [
    "### En couleur pour être affiché et annoté par les personnes: rainbow Gloubi-boulga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2c3b38-80f8-4d4f-b260-564c30c9c6e0",
   "metadata": {},
   "source": [
    "#### Sauvegarde en 1 seul fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "60fbd8c2-56b5-41dd-882f-5c7100020eff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export_path=\"data/test/small_1file/\"\n",
    "with open(export_path+\"gloubiboulga_colorfull_update.jsonl\", 'w') as corpus_file:\n",
    "    for filename in liste_test_export:\n",
    "        idx_parag=0        \n",
    "        for parag in dico_all_parag_select[filename]:\n",
    "            parag=corrections_espaces_et_tirets(parag)\n",
    "            source_file, cible_file=filename.split('.')[0], filename.split('.')[1]\n",
    "            liste_parag1, liste_parag2,list_intentions =[], [], []\n",
    "            list_intentions=[]\n",
    "            for phrase in parag[0]:\n",
    "                if phrase[\"couleur\"]==\"black\":\n",
    "                    if \"list_intentions\" in phrase.keys():\n",
    "                        list_intentions=phrase[\"list_intentions\"]\n",
    "                    else:\n",
    "                        list_intentions=[]\n",
    "                else:\n",
    "                    liste_parag1.append({\"color\":phrase[\"couleur\"],\"text\":remove_tags_avec_espaces(phrase[\"text\"])})\n",
    "            for phrase in parag[1]:\n",
    "                if phrase[\"couleur\"]==\"black\":\n",
    "                    if \"list_intentions\" in phrase.keys():\n",
    "                        list_intentions=phrase[\"list_intentions\"]\n",
    "                    else:\n",
    "                        list_intentions=[]\n",
    "                else:\n",
    "                    liste_parag2.append({\"color\":phrase[\"couleur\"],\"text\":remove_tags_avec_espaces(phrase[\"text\"])})\n",
    "\n",
    "            json.dump({'id_source':source_file,\"id_cible\":cible_file,\"index_paragraph\":idx_parag,\"id_paragraph\":filename+'.'+str(idx_parag).zfill(2),\n",
    "                       \"parag-1\":liste_parag1,\n",
    "                       \"parag-2\":liste_parag2\n",
    "                      },corpus_file)\n",
    "            idx_parag+=1\n",
    "            corpus_file.write('\\n')       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8231f00d-657f-4507-a3cc-77089077e253",
   "metadata": {},
   "source": [
    "### En json classique pour être donné à un modèle: Gloubi-boulga nature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c45ef8a7-2c45-4414-af4c-a6702f308253",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def recollage_sentence(sentence):                          \n",
    "    end_with_space=True\n",
    "    sentence_complet=\"\"\n",
    "    for ligne in sentence:\n",
    "        if len(ligne)>0:\n",
    "            start_with_space=(ligne[0]==' ')\n",
    "            if end_with_space or start_with_space:\n",
    "                sentence_complet+=ligne\n",
    "            else:\n",
    "                sentence_complet+=' '\n",
    "                sentence_complet+=ligne\n",
    "            end_with_space=(ligne[-1]==' ')\n",
    "    return  sentence_complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "262e7a53-df2a-48a9-9a9c-555616f3afee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_list_sentences(parag):\n",
    "    liste_parag=[]\n",
    "    wait_for_blue=True\n",
    "    liste_blue=[]\n",
    "    for phrase in parag:\n",
    "        if phrase[\"couleur\"]==\"black\":\n",
    "            if not(wait_for_blue):\n",
    "                liste_parag.append({\"text\":recollage_sentence(liste_blue)})\n",
    "                wait_for_blue=True\n",
    "                liste_blue=[]            \n",
    "        elif (phrase[\"couleur\"] in [\"blue\",\"cyan\"]):\n",
    "            liste_blue.append(remove_tags_avec_espaces(phrase[\"text\"]))\n",
    "            wait_for_blue=False\n",
    "        elif (phrase[\"couleur\"] ==\"green\"):\n",
    "            liste_parag.append({\"text\":remove_tags_avec_espaces(phrase[\"text\"])})\n",
    "        else:\n",
    "            liste_parag.append({\"text\":remove_tags_avec_espaces(phrase[\"text\"])})\n",
    "    if not(wait_for_blue):\n",
    "                liste_parag.append({\"text\":recollage_sentence(liste_blue)})     \n",
    "    return liste_parag            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "938151cf-5a83-410f-8987-d64df9e71afb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export_path=\"data/test/small_1file/\"\n",
    "with open(export_path+\"gloubiboulga_update.jsonl\", 'w', encoding='utf8') as corpus_file:\n",
    "    for filename in liste_test_export:\n",
    "        idx_parag=0   \n",
    "        for parag in dico_all_parag_select[filename]:\n",
    "            parag=corrections_espaces_et_tirets(parag)\n",
    "            source_file=filename.split('.')[0]\n",
    "            cible_file=filename.split('.')[1]\n",
    "            liste_sentences_1,liste_sentences_2=get_list_sentences(parag[0]),get_list_sentences(parag[1])\n",
    "            liste_parag1=[remove_tags_avec_espaces(phrase[\"text\"]) for phrase in parag[0] if phrase[\"couleur\"]!=\"black\"]\n",
    "            liste_parag2=[remove_tags_avec_espaces(phrase[\"text\"]) for phrase in parag[1] if phrase[\"couleur\"]!=\"black\"]\n",
    "            parag1,parag2=recollage_parag_nocolor(liste_parag1,liste_parag2)\n",
    "            json.dump({'id_source':source_file,\"id_cible\":cible_file,\"index_paragraph\":idx_parag,\"id_paragraph\":filename+'.'+str(idx_parag).zfill(2),\n",
    "                       \"parag-1\":parag1,\n",
    "                       \"parag-2\":parag2,\n",
    "                       \"list-sentences-1\": liste_sentences_1,\n",
    "                       \"list-sentences-2\": liste_sentences_2\n",
    "                      },corpus_file, ensure_ascii=False)\n",
    "            idx_parag+=1\n",
    "            corpus_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9a0f60-c8e7-4539-aba5-1d24cc4b6d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
